{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZHSwmES2eLQvOQ+G4xUhV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "7ovABqndutsN",
        "outputId": "277c64c6-ecb6-4ab2-cf9b-7b44ca95b74b"
      },
      "source": [
        "!pip install q keras==2.2.4\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.7/dist-packages (2.6)\n",
            "Collecting keras==2.2.4\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ON7kzGQvlnN",
        "outputId": "a92aa0ff-8d35-4364-b220-e3ed1ed1d2a9"
      },
      "source": [
        "%tensorflow_version 1.15.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.5`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVAsV4OXvcQE",
        "outputId": "7d2b893b-402a-45fa-d955-108015a8d33d"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "print(\"Tensorflow version %s\" %tf.__version__)\r\n",
        "print(\"Keras version %s\" %keras.__version__)\r\n",
        "\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Keras version 2.4.3\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHkHclRnvhQI",
        "outputId": "0ea34cbf-2074-4cce-b89b-1d4302e3e27f"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "!pip3 install pickle5\r\n",
        "import pickle5 as pickle\r\n",
        "import pandas as pd\r\n",
        "with open('/content/drive/MyDrive/processed_data_frame_new.pkl', \"rb\") as fh:\r\n",
        "  data = pickle.load(fh)\r\n",
        "dataframe = pd.DataFrame(data)\r\n",
        "#read_pickle('/content/drive/MyDrive/processed_data_frame.pkl')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219274 sha256=c0de3942775fdd323d9b53576f20c3b7132c609090c97bd715303b2b9b1ee586\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e4ut1Y6zdXs"
      },
      "source": [
        "dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHv0-kJ1vhYv"
      },
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\r\n",
        "#from keras.utils import to_categorical\r\n",
        "\r\n",
        "# Convert features and corresponding classification labels into numpy arrays\r\n",
        "X = np.array(dataframe.feature.tolist())\r\n",
        "y = np.array(dataframe.class_label.tolist())\r\n",
        "\r\n",
        "# no need to encode labels since they are already in form of one hot encode\r\n",
        "\r\n",
        "# delete dataframe to save memory\r\n",
        "#reset_selective -f dataframe\r\n",
        "\r\n",
        "# split the dataset \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\r\n",
        "\r\n",
        "# delete X to save memory\r\n",
        "#reset_selective -f X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6DO31nrreb"
      },
      "source": [
        "## baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u65NKa2RroZV",
        "outputId": "39fcb4a8-c43a-45b2-bcd3-00c0a68ab773"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\r\n",
        "                            Conv2D, MaxPooling2D, Reshape, GRU\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import Input, optimizers\r\n",
        "\r\n",
        "num_rows = X.shape[1]\r\n",
        "num_columns = X.shape[2]\r\n",
        "num_channels = 1\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\r\n",
        "\r\n",
        "num_labels = y.shape[2]\r\n",
        "#num_labels = 16\r\n",
        "\r\n",
        "def Net(dilated_kernel, dilation, dilated_padding):\r\n",
        "    \r\n",
        "    # input layer\r\n",
        "    inputs = Input(shape=(num_rows, num_columns, num_channels))\r\n",
        "    \r\n",
        "    # DWS-CNN layer 1\r\n",
        "    x = ZeroPadding2D(padding=(2))(inputs)\r\n",
        "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 2\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 3\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    x = Reshape((1024, 256))(x)\r\n",
        "    \r\n",
        "    # GRU\r\n",
        "    #x = ZeroPadding2D(padding=(dilated_padding*dilation, 1))(x)\r\n",
        "    #x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(dilation, 1))(x)\r\n",
        "    #x = BatchNormalization()(x)\r\n",
        "    #x = Activation('relu')(x)\r\n",
        "    x = GRU(256, return_sequences=True)(x)\r\n",
        "        \r\n",
        "    # classifier layer\r\n",
        "    outputs = Dense(num_labels,activation='sigmoid')(x)\r\n",
        "    \r\n",
        "    \r\n",
        "    # model compilation for training\r\n",
        "    adam = optimizers.Adam(lr=0.0001)\r\n",
        "    model = Model(inputs, outputs)                            \r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "# create the model\r\n",
        "dilated_kernel = (3,3)\r\n",
        "dilation = 10\r\n",
        "dilated_padding = 1\r\n",
        "model = Net(dilated_kernel,dilation,dilated_padding)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1024, 40, 1)]     0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 1028, 44, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 1024, 40, 256)     6656      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1024, 40, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024, 40, 256)     1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 1028, 12, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1024, 8, 256)      1638656   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 1028, 6, 256)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1024, 2, 256)      1638656   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024, 2, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 1024, 256)         0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 1024, 256)         394752    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024, 16)          4112      \n",
            "=================================================================\n",
            "Total params: 3,685,904\n",
            "Trainable params: 3,684,368\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U6wFvCWEGun"
      },
      "source": [
        "## Dessed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_24V80EGal",
        "outputId": "fb03362e-fb59-47c1-ccb1-2f78b3bf9b44"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\r\n",
        "                            Conv2D, MaxPooling2D, Reshape, GRU\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import Input, optimizers\r\n",
        "\r\n",
        "num_rows = X.shape[1]\r\n",
        "num_columns = X.shape[2]\r\n",
        "num_channels = 1\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\r\n",
        "\r\n",
        "num_labels = y.shape[2]\r\n",
        "#num_labels = 16\r\n",
        "\r\n",
        "def Net():\r\n",
        "    \r\n",
        "    # input layer\r\n",
        "    inputs = Input(shape=(num_rows, num_columns, num_channels))\r\n",
        "    \r\n",
        "    # DWS-CNN layer 1\r\n",
        "    x = ZeroPadding2D(padding=(2))(inputs)\r\n",
        "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 2\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 3\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    x = Reshape((1024, 256))(x)\r\n",
        "    \r\n",
        "    # GRU\r\n",
        "    x = GRU(256, return_sequences=True)(x)\r\n",
        "        \r\n",
        "    # classifier layer\r\n",
        "    outputs = Dense(num_labels,activation='sigmoid')(x)\r\n",
        "    \r\n",
        "    \r\n",
        "    # model compilation for training\r\n",
        "    adam = optimizers.Adam(lr=0.0001)\r\n",
        "    model = Model(inputs, outputs)                            \r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "# create the model\r\n",
        "dilated_kernel = (3,3)\r\n",
        "dilation = 10\r\n",
        "dilated_padding = 1\r\n",
        "model = Net()\r\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1024, 40, 1)]     0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 1028, 44, 1)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d (SeparableC (None, 1024, 40, 256)     537       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1024, 40, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024, 40, 256)     1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 1028, 12, 256)     0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 1024, 8, 256)      72192     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 1028, 6, 256)      0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 1024, 2, 256)      72192     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024, 2, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 1024, 256)         0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 1024, 256)         394752    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024, 16)          4112      \n",
            "=================================================================\n",
            "Total params: 546,857\n",
            "Trainable params: 545,321\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr-7W-6GvaYp"
      },
      "source": [
        "## Baseline dilated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "sau4io1ZvaCi",
        "outputId": "a2a01d5b-2596-4d9d-f24d-7da1baa71869"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\r\n",
        "                            Conv2D, MaxPooling2D, Reshape, Permute\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import Input, optimizers\r\n",
        "\r\n",
        "num_rows = X.shape[1]\r\n",
        "num_columns = X.shape[2]\r\n",
        "num_channels = 1\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\r\n",
        "\r\n",
        "num_labels = y.shape[2]\r\n",
        "#num_labels = 16\r\n",
        "\r\n",
        "def Net(dilated_kernel, dilation, dilated_padding):\r\n",
        "    \r\n",
        "    # input layer\r\n",
        "    inputs = Input(shape=(num_rows, num_columns, num_channels))\r\n",
        "    \r\n",
        "    # DWS-CNN layer 1\r\n",
        "    #x = ZeroPadding2D(padding=(2))(inputs)\r\n",
        "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(inputs)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,5), padding='same')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 2\r\n",
        "    #x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,4), padding='same')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 3\r\n",
        "    #x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,2), padding='same')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    #x = Reshape((1024, 256))(x)\r\n",
        "    #x = Reshape((1024, 256, 1))(x)\r\n",
        "    x = Permute((1,3,2))(x)\r\n",
        "    #x = Permute((3,2,1))(x)\r\n",
        "    \r\n",
        "    # DIL-CNN \r\n",
        "    x = ZeroPadding2D(padding=(dilated_padding*dilation, 0))(x)\r\n",
        "    x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(dilation, 1), strides=(1,3))(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    \r\n",
        "    #x = Permute((2,1,3))(x)\r\n",
        "    \r\n",
        "    x = Reshape((1024, 256*85))(x)\r\n",
        "    \r\n",
        "    # classifier layer\r\n",
        "    outputs = Dense(num_labels,activation='sigmoid')(x)\r\n",
        "    \r\n",
        "    \r\n",
        "    # model compilation for training\r\n",
        "    adam = optimizers.Adam(lr=0.0001)\r\n",
        "    model = Model(inputs, outputs)                            \r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "# create the model\r\n",
        "dilated_kernel = (3,3)\r\n",
        "dilation = 10\r\n",
        "dilated_padding = 1\r\n",
        "model = Net(dilated_kernel,dilation,dilated_padding)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-85c8d0aa673c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mdilation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mdilated_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilated_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdilated_padding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-85c8d0aa673c>\u001b[0m in \u001b[0;36mNet\u001b[0;34m(dilated_kernel, dilation, dilated_padding)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# DIL-CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilated_padding\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilated_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             outputs = K.conv3d(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format, filters, dilations)\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution)\u001b[0m\n\u001b[1;32m   1023\u001b[0m           \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m   1026\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n\u001b[0;32m-> 1091\u001b[0;31m         num_spatial_dims, strides, dilation_rate)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_get_strides_and_dilation_rate\u001b[0;34m(num_spatial_dims, strides, dilation_rate)\u001b[0m\n\u001b[1;32m    758\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     raise ValueError(\n\u001b[0;32m--> 760\u001b[0;31m         \"strides > 1 not supported in conjunction with dilation_rate > 1\")\n\u001b[0m\u001b[1;32m    761\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: strides > 1 not supported in conjunction with dilation_rate > 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-DedsknrpJn"
      },
      "source": [
        "## new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ICNx-O8vhbQ",
        "outputId": "b312fbc4-6dd8-4bdb-e7be-b750e410dc9a"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\r\n",
        "                            Conv2D, MaxPooling2D, Reshape, Permute\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import Input, optimizers\r\n",
        "\r\n",
        "num_rows = X.shape[1]\r\n",
        "num_columns = X.shape[2]\r\n",
        "num_channels = 1\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\r\n",
        "\r\n",
        "num_labels = y.shape[2]\r\n",
        "#num_labels = 16\r\n",
        "\r\n",
        "def Net(dilated_kernel, dilation, dilated_padding):\r\n",
        "    \r\n",
        "    # input layer\r\n",
        "    inputs = Input(shape=(num_rows, num_columns, num_channels))\r\n",
        "    \r\n",
        "    # DWS-CNN layer 1\r\n",
        "    x = ZeroPadding2D(padding=(2))(inputs)\r\n",
        "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 2\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    # DWS-CNN layer 3\r\n",
        "    x = ZeroPadding2D(padding=(2))(x)\r\n",
        "    # use valid padding since padding is introduced before due to its special form\r\n",
        "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    # Batch Normalisation before passing it to the next layer\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    # Pooling\r\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\r\n",
        "    # Dropout\r\n",
        "    x = Dropout(0.25)(x)\r\n",
        "    \r\n",
        "    x = Permute((1,3,2))(x)\r\n",
        "    \r\n",
        "    # DIL-CNN \r\n",
        "    x = ZeroPadding2D(padding=(dilated_padding*dilation, 0))(x)\r\n",
        "    x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(dilation, 1))(x)#, strides=(1,3))(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    initializer = keras.initializers.Ones()\r\n",
        "    x = Conv2D(256, (1,1), strides=(1,3), kernel_initializer=initializer)(x)\r\n",
        "    \r\n",
        "    x = Reshape((1024, 256*84))(x)\r\n",
        "    \r\n",
        "    # classifier layer\r\n",
        "    outputs = Dense(num_labels,activation='sigmoid')(x)\r\n",
        "    \r\n",
        "    \r\n",
        "    # model compilation for training\r\n",
        "    adam = optimizers.Adam()#lr=0.0001)\r\n",
        "    model = Model(inputs, outputs)                            \r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "# create the model\r\n",
        "dilated_kernel = (5,5)\r\n",
        "dilation = 10\r\n",
        "dilated_padding = 2\r\n",
        "model = Net(dilated_kernel,dilation,dilated_padding)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1024, 40, 1)]     0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPaddi (None, 1028, 44, 1)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 1024, 40, 256)     537       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 1024, 40, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 1024, 40, 256)     1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPaddi (None, 1028, 12, 256)     0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_10 (Separab (None, 1024, 8, 256)      72192     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 1024, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 1024, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPaddi (None, 1028, 6, 256)      0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_11 (Separab (None, 1024, 2, 256)      72192     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1024, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1024, 2, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024, 1, 256)      0         \n",
            "_________________________________________________________________\n",
            "permute_2 (Permute)          (None, 1024, 256, 1)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPaddi (None, 1064, 256, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1024, 252, 256)    6656      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1024, 252, 256)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1024, 252, 256)    1024      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1024, 84, 256)     65792     \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 1024, 21504)       0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024, 16)          344080    \n",
            "=================================================================\n",
            "Total params: 565,545\n",
            "Trainable params: 563,497\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNzMSCbW4Cv5"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZbIeHH1vheD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b378fb-426a-448d-9ee1-9bc81b792be5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "from datetime import datetime \r\n",
        "\r\n",
        "num_epochs = 250\r\n",
        "# low batch size due to memory maximum dimension, modify if using smaller dataset\r\n",
        "num_batch_size = 16\r\n",
        "\r\n",
        "callbacks = [ModelCheckpoint(filepath='/content/drive/MyDrive/model-{val_loss:.2f}_dessed.h5', \r\n",
        "                               verbose=1, save_best_only=True, monitor=\"val_loss\"),\r\n",
        "                EarlyStopping(monitor='val_loss', patience=30)]\r\n",
        "\r\n",
        "start = datetime.now()\r\n",
        "\r\n",
        "#y_train = y_train.reshape(y_train.shape[0], 1024, 16)\r\n",
        "#y_test = y_test.reshape(y_test.shape[0], 1024, 16)\r\n",
        "\r\n",
        "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_split=0.16, verbose=1, callbacks=callbacks)\r\n",
        "\r\n",
        "duration = datetime.now() - start\r\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "142/142 [==============================] - 77s 298ms/step - loss: 0.4266 - binary_accuracy: 0.7965 - val_loss: 0.7132 - val_binary_accuracy: 0.3530\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.71324, saving model to /content/drive/MyDrive/model-0.71_dessed.h5\n",
            "Epoch 2/250\n",
            "142/142 [==============================] - 41s 287ms/step - loss: 0.2102 - binary_accuracy: 0.9294 - val_loss: 0.6062 - val_binary_accuracy: 0.6918\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.71324 to 0.60616, saving model to /content/drive/MyDrive/model-0.61_dessed.h5\n",
            "Epoch 3/250\n",
            "142/142 [==============================] - 40s 283ms/step - loss: 0.1983 - binary_accuracy: 0.9339 - val_loss: 0.2854 - val_binary_accuracy: 0.9112\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.60616 to 0.28538, saving model to /content/drive/MyDrive/model-0.29_dessed.h5\n",
            "Epoch 4/250\n",
            "142/142 [==============================] - 41s 286ms/step - loss: 0.1935 - binary_accuracy: 0.9353 - val_loss: 0.1989 - val_binary_accuracy: 0.9332\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.28538 to 0.19887, saving model to /content/drive/MyDrive/model-0.20_dessed.h5\n",
            "Epoch 5/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1864 - binary_accuracy: 0.9384 - val_loss: 0.1776 - val_binary_accuracy: 0.9419\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.19887 to 0.17764, saving model to /content/drive/MyDrive/model-0.18_dessed.h5\n",
            "Epoch 6/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1834 - binary_accuracy: 0.9394 - val_loss: 0.1743 - val_binary_accuracy: 0.9429\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.17764 to 0.17426, saving model to /content/drive/MyDrive/model-0.17_dessed.h5\n",
            "Epoch 7/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1791 - binary_accuracy: 0.9405 - val_loss: 0.1693 - val_binary_accuracy: 0.9442\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.17426 to 0.16930, saving model to /content/drive/MyDrive/model-0.17_dessed.h5\n",
            "Epoch 8/250\n",
            "142/142 [==============================] - 40s 283ms/step - loss: 0.1748 - binary_accuracy: 0.9424 - val_loss: 0.1716 - val_binary_accuracy: 0.9442\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.16930\n",
            "Epoch 9/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1738 - binary_accuracy: 0.9423 - val_loss: 0.1652 - val_binary_accuracy: 0.9461\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.16930 to 0.16515, saving model to /content/drive/MyDrive/model-0.17_dessed.h5\n",
            "Epoch 10/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1744 - binary_accuracy: 0.9421 - val_loss: 0.1641 - val_binary_accuracy: 0.9461\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.16515 to 0.16412, saving model to /content/drive/MyDrive/model-0.16_dessed.h5\n",
            "Epoch 11/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1678 - binary_accuracy: 0.9444 - val_loss: 0.1629 - val_binary_accuracy: 0.9463\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.16412 to 0.16288, saving model to /content/drive/MyDrive/model-0.16_dessed.h5\n",
            "Epoch 12/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1659 - binary_accuracy: 0.9448 - val_loss: 0.1599 - val_binary_accuracy: 0.9480\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.16288 to 0.15988, saving model to /content/drive/MyDrive/model-0.16_dessed.h5\n",
            "Epoch 13/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1649 - binary_accuracy: 0.9456 - val_loss: 0.1578 - val_binary_accuracy: 0.9485\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.15988 to 0.15775, saving model to /content/drive/MyDrive/model-0.16_dessed.h5\n",
            "Epoch 14/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1625 - binary_accuracy: 0.9468 - val_loss: 0.1595 - val_binary_accuracy: 0.9480\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.15775\n",
            "Epoch 15/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1608 - binary_accuracy: 0.9469 - val_loss: 0.1569 - val_binary_accuracy: 0.9488\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.15775 to 0.15692, saving model to /content/drive/MyDrive/model-0.16_dessed.h5\n",
            "Epoch 16/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1599 - binary_accuracy: 0.9472 - val_loss: 0.1530 - val_binary_accuracy: 0.9505\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.15692 to 0.15299, saving model to /content/drive/MyDrive/model-0.15_dessed.h5\n",
            "Epoch 17/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1559 - binary_accuracy: 0.9491 - val_loss: 0.1537 - val_binary_accuracy: 0.9506\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.15299\n",
            "Epoch 18/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1544 - binary_accuracy: 0.9495 - val_loss: 0.1551 - val_binary_accuracy: 0.9493\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15299\n",
            "Epoch 19/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1522 - binary_accuracy: 0.9500 - val_loss: 0.1532 - val_binary_accuracy: 0.9497\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.15299\n",
            "Epoch 20/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1517 - binary_accuracy: 0.9509 - val_loss: 0.1510 - val_binary_accuracy: 0.9510\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.15299 to 0.15100, saving model to /content/drive/MyDrive/model-0.15_dessed.h5\n",
            "Epoch 21/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1515 - binary_accuracy: 0.9506 - val_loss: 0.1526 - val_binary_accuracy: 0.9498\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.15100\n",
            "Epoch 22/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1492 - binary_accuracy: 0.9515 - val_loss: 0.1498 - val_binary_accuracy: 0.9511\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.15100 to 0.14983, saving model to /content/drive/MyDrive/model-0.15_dessed.h5\n",
            "Epoch 23/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1454 - binary_accuracy: 0.9527 - val_loss: 0.1501 - val_binary_accuracy: 0.9518\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.14983\n",
            "Epoch 24/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1487 - binary_accuracy: 0.9513 - val_loss: 0.1452 - val_binary_accuracy: 0.9532\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.14983 to 0.14525, saving model to /content/drive/MyDrive/model-0.15_dessed.h5\n",
            "Epoch 25/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1465 - binary_accuracy: 0.9526 - val_loss: 0.1464 - val_binary_accuracy: 0.9529\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.14525\n",
            "Epoch 26/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1475 - binary_accuracy: 0.9513 - val_loss: 0.1479 - val_binary_accuracy: 0.9526\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.14525\n",
            "Epoch 27/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1431 - binary_accuracy: 0.9529 - val_loss: 0.1454 - val_binary_accuracy: 0.9530\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.14525\n",
            "Epoch 28/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1446 - binary_accuracy: 0.9525 - val_loss: 0.1431 - val_binary_accuracy: 0.9547\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.14525 to 0.14306, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 29/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1408 - binary_accuracy: 0.9542 - val_loss: 0.1450 - val_binary_accuracy: 0.9533\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.14306\n",
            "Epoch 30/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1408 - binary_accuracy: 0.9547 - val_loss: 0.1442 - val_binary_accuracy: 0.9531\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.14306\n",
            "Epoch 31/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1406 - binary_accuracy: 0.9541 - val_loss: 0.1443 - val_binary_accuracy: 0.9538\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.14306\n",
            "Epoch 32/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1383 - binary_accuracy: 0.9552 - val_loss: 0.1430 - val_binary_accuracy: 0.9544\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.14306 to 0.14304, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 33/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1367 - binary_accuracy: 0.9558 - val_loss: 0.1432 - val_binary_accuracy: 0.9538\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.14304\n",
            "Epoch 34/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1359 - binary_accuracy: 0.9560 - val_loss: 0.1402 - val_binary_accuracy: 0.9555\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.14304 to 0.14024, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 35/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1327 - binary_accuracy: 0.9576 - val_loss: 0.1408 - val_binary_accuracy: 0.9555\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.14024\n",
            "Epoch 36/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1352 - binary_accuracy: 0.9560 - val_loss: 0.1398 - val_binary_accuracy: 0.9554\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.14024 to 0.13982, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 37/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1321 - binary_accuracy: 0.9576 - val_loss: 0.1415 - val_binary_accuracy: 0.9549\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.13982\n",
            "Epoch 38/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1330 - binary_accuracy: 0.9569 - val_loss: 0.1407 - val_binary_accuracy: 0.9552\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.13982\n",
            "Epoch 39/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1306 - binary_accuracy: 0.9577 - val_loss: 0.1394 - val_binary_accuracy: 0.9557\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.13982 to 0.13937, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 40/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1333 - binary_accuracy: 0.9564 - val_loss: 0.1388 - val_binary_accuracy: 0.9560\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.13937 to 0.13877, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 41/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1299 - binary_accuracy: 0.9583 - val_loss: 0.1405 - val_binary_accuracy: 0.9552\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.13877\n",
            "Epoch 42/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1306 - binary_accuracy: 0.9577 - val_loss: 0.1391 - val_binary_accuracy: 0.9556\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.13877\n",
            "Epoch 43/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1281 - binary_accuracy: 0.9590 - val_loss: 0.1399 - val_binary_accuracy: 0.9551\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.13877\n",
            "Epoch 44/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1275 - binary_accuracy: 0.9589 - val_loss: 0.1399 - val_binary_accuracy: 0.9553\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.13877\n",
            "Epoch 45/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1258 - binary_accuracy: 0.9598 - val_loss: 0.1370 - val_binary_accuracy: 0.9568\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.13877 to 0.13698, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 46/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1242 - binary_accuracy: 0.9602 - val_loss: 0.1382 - val_binary_accuracy: 0.9562\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.13698\n",
            "Epoch 47/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1249 - binary_accuracy: 0.9599 - val_loss: 0.1365 - val_binary_accuracy: 0.9568\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.13698 to 0.13646, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 48/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1223 - binary_accuracy: 0.9607 - val_loss: 0.1376 - val_binary_accuracy: 0.9568\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.13646\n",
            "Epoch 49/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1246 - binary_accuracy: 0.9600 - val_loss: 0.1372 - val_binary_accuracy: 0.9567\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.13646\n",
            "Epoch 50/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1234 - binary_accuracy: 0.9604 - val_loss: 0.1366 - val_binary_accuracy: 0.9567\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.13646\n",
            "Epoch 51/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1198 - binary_accuracy: 0.9620 - val_loss: 0.1367 - val_binary_accuracy: 0.9574\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.13646\n",
            "Epoch 52/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1230 - binary_accuracy: 0.9607 - val_loss: 0.1366 - val_binary_accuracy: 0.9572\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.13646\n",
            "Epoch 53/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1207 - binary_accuracy: 0.9615 - val_loss: 0.1381 - val_binary_accuracy: 0.9566\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.13646\n",
            "Epoch 54/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1197 - binary_accuracy: 0.9618 - val_loss: 0.1386 - val_binary_accuracy: 0.9565\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.13646\n",
            "Epoch 55/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1208 - binary_accuracy: 0.9616 - val_loss: 0.1363 - val_binary_accuracy: 0.9575\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.13646 to 0.13634, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 56/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1177 - binary_accuracy: 0.9626 - val_loss: 0.1358 - val_binary_accuracy: 0.9574\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.13634 to 0.13577, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 57/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1177 - binary_accuracy: 0.9626 - val_loss: 0.1363 - val_binary_accuracy: 0.9576\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.13577\n",
            "Epoch 58/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1158 - binary_accuracy: 0.9633 - val_loss: 0.1353 - val_binary_accuracy: 0.9578\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.13577 to 0.13529, saving model to /content/drive/MyDrive/model-0.14_dessed.h5\n",
            "Epoch 59/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1183 - binary_accuracy: 0.9624 - val_loss: 0.1358 - val_binary_accuracy: 0.9577\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.13529\n",
            "Epoch 60/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1154 - binary_accuracy: 0.9631 - val_loss: 0.1362 - val_binary_accuracy: 0.9579\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.13529\n",
            "Epoch 61/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1165 - binary_accuracy: 0.9630 - val_loss: 0.1377 - val_binary_accuracy: 0.9570\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.13529\n",
            "Epoch 62/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1139 - binary_accuracy: 0.9639 - val_loss: 0.1391 - val_binary_accuracy: 0.9567\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.13529\n",
            "Epoch 63/250\n",
            "142/142 [==============================] - 41s 285ms/step - loss: 0.1108 - binary_accuracy: 0.9650 - val_loss: 0.1372 - val_binary_accuracy: 0.9570\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.13529\n",
            "Epoch 64/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1109 - binary_accuracy: 0.9650 - val_loss: 0.1398 - val_binary_accuracy: 0.9558\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.13529\n",
            "Epoch 65/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1109 - binary_accuracy: 0.9649 - val_loss: 0.1358 - val_binary_accuracy: 0.9580\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.13529\n",
            "Epoch 66/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1110 - binary_accuracy: 0.9649 - val_loss: 0.1378 - val_binary_accuracy: 0.9581\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.13529\n",
            "Epoch 67/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1080 - binary_accuracy: 0.9660 - val_loss: 0.1364 - val_binary_accuracy: 0.9578\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.13529\n",
            "Epoch 68/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1108 - binary_accuracy: 0.9650 - val_loss: 0.1381 - val_binary_accuracy: 0.9576\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.13529\n",
            "Epoch 69/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1100 - binary_accuracy: 0.9654 - val_loss: 0.1378 - val_binary_accuracy: 0.9574\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.13529\n",
            "Epoch 70/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1100 - binary_accuracy: 0.9651 - val_loss: 0.1377 - val_binary_accuracy: 0.9576\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.13529\n",
            "Epoch 71/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1074 - binary_accuracy: 0.9660 - val_loss: 0.1367 - val_binary_accuracy: 0.9578\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.13529\n",
            "Epoch 72/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1072 - binary_accuracy: 0.9661 - val_loss: 0.1367 - val_binary_accuracy: 0.9581\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.13529\n",
            "Epoch 73/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1086 - binary_accuracy: 0.9656 - val_loss: 0.1394 - val_binary_accuracy: 0.9572\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.13529\n",
            "Epoch 74/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1090 - binary_accuracy: 0.9650 - val_loss: 0.1396 - val_binary_accuracy: 0.9571\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.13529\n",
            "Epoch 75/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1071 - binary_accuracy: 0.9662 - val_loss: 0.1370 - val_binary_accuracy: 0.9581\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.13529\n",
            "Epoch 76/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1050 - binary_accuracy: 0.9670 - val_loss: 0.1385 - val_binary_accuracy: 0.9573\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.13529\n",
            "Epoch 77/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1023 - binary_accuracy: 0.9679 - val_loss: 0.1376 - val_binary_accuracy: 0.9575\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.13529\n",
            "Epoch 78/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1037 - binary_accuracy: 0.9674 - val_loss: 0.1396 - val_binary_accuracy: 0.9570\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.13529\n",
            "Epoch 79/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1043 - binary_accuracy: 0.9671 - val_loss: 0.1398 - val_binary_accuracy: 0.9577\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.13529\n",
            "Epoch 80/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1040 - binary_accuracy: 0.9671 - val_loss: 0.1384 - val_binary_accuracy: 0.9584\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.13529\n",
            "Epoch 81/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1035 - binary_accuracy: 0.9676 - val_loss: 0.1403 - val_binary_accuracy: 0.9569\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.13529\n",
            "Epoch 82/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.1023 - binary_accuracy: 0.9679 - val_loss: 0.1402 - val_binary_accuracy: 0.9571\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.13529\n",
            "Epoch 83/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1032 - binary_accuracy: 0.9676 - val_loss: 0.1403 - val_binary_accuracy: 0.9568\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.13529\n",
            "Epoch 84/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.1015 - binary_accuracy: 0.9682 - val_loss: 0.1403 - val_binary_accuracy: 0.9575\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.13529\n",
            "Epoch 85/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.0993 - binary_accuracy: 0.9688 - val_loss: 0.1381 - val_binary_accuracy: 0.9582\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.13529\n",
            "Epoch 86/250\n",
            "142/142 [==============================] - 40s 284ms/step - loss: 0.0977 - binary_accuracy: 0.9697 - val_loss: 0.1458 - val_binary_accuracy: 0.9562\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.13529\n",
            "Epoch 87/250\n",
            "142/142 [==============================] - 40s 285ms/step - loss: 0.0986 - binary_accuracy: 0.9688 - val_loss: 0.1410 - val_binary_accuracy: 0.9568\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.13529\n",
            "Epoch 88/250\n",
            "142/142 [==============================] - 41s 285ms/step - loss: 0.0984 - binary_accuracy: 0.9691 - val_loss: 0.1420 - val_binary_accuracy: 0.9569\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.13529\n",
            "Training completed in time:  0:59:56.979724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D80dzXbzmjpB"
      },
      "source": [
        "model.save('/content/drive/MyDrive/dessed-0.13.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcgsF2fZvhgj",
        "outputId": "11122f83-bf1a-4f5e-a53d-0837aca39c6e"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\r\n",
        "print(\"Evaluate on test data\")\r\n",
        "results = model.evaluate(x_test, y_test, batch_size=num_batch_size)\r\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "43/43 [==============================] - 4s 78ms/step - loss: 0.1524 - binary_accuracy: 0.9533\n",
            "test loss, test acc: [0.1524072289466858, 0.9532897472381592]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "z2ZOVgAMvhil",
        "outputId": "cc0f61bf-b86a-4207-effb-75f5c75fe3e6"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(history.history['binary_accuracy'])\r\n",
        "plt.plot(history.history['val_binary_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hc9X3v+/d3bprRXbbkq2xswNwvBowLuXRDbjWQQlISQlKy0+62pM8TmnQ3YQd2k/SEc3Z32uyTZmdvciEJuzRpIJQ0jXtiyiUFQptAbBxCsI3BNhhLNraQrbtG0sx8zx+/JVmWZVs2Go3t9Xk9j57RrLVmrZ/G4/WZ3/pdlrk7IiISX4lKF0BERCpLQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBCZIjP7WzP7f6a47Stm9o43uh+RmaAgEBGJOQWBiEjMKQjkpBJdkrnVzJ4zs34z+7aZzTWzB82s18weNbOmcdtfa2YbzKzLzB43s7PHrbvIzNZHr/s+kJ1wrHeb2bPRa39mZhccY5n/yMy2mNleM1ttZgui5WZmf2Nme8ysx8x+bWbnReuuNrONUdnazexTx/SGiaAgkJPT9cA7gTOA3wYeBP4r0EL4zH8cwMzOAO4F/jRatwb4ZzPLmFkG+CfgO8As4B+i/RK99iLgbuCjwGzgG8BqM6s6moKa2duA/w7cAMwHtgP3RavfBfxm9Hc0RNt0Ruu+DXzU3euA84B/PZrjioynIJCT0f9y993u3g48CTzt7r909zzwQ+CiaLsPAD9290fcfQT4H0AOeBNwGZAGvuzuI+7+ALB23DFuBr7h7k+7e9Hd7wGGotcdjd8F7nb39e4+BNwOXG5mS4ARoA44CzB33+Tuu6LXjQDnmFm9u+9z9/VHeVyRMQoCORntHvf74CTPa6PfFxC+gQPg7iVgB7AwWtfuB87KuH3c76cAn4wuC3WZWRewKHrd0ZhYhj7Ct/6F7v6vwP8G7gT2mNldZlYfbXo9cDWw3cyeMLPLj/K4ImMUBBJnOwkndCBckyeczNuBXcDCaNmoxeN+3wH8N3dvHPdT7e73vsEy1BAuNbUDuPtX3P0S4BzCJaJbo+Vr3f06YA7hEtb9R3lckTEKAomz+4FrzOztZpYGPkm4vPMz4OdAAfi4maXN7HeAleNe+03gj83sN6JG3Rozu8bM6o6yDPcCv29my6P2hb8kXMp6xcwujfafBvqBPFCK2jB+18waoktaPUDpDbwPEnMKAoktd98M3AT8L+B1QsPyb7v7sLsPA78D/B6wl9Ce8I/jXrsO+CPCpZt9wJZo26Mtw6PAZ4EfEGohpwE3RqvrCYGzj3D5qBP4YrTuw8ArZtYD/DGhrUHkmJhuTCMiEm+qEYiIxJyCQEQk5hQEIiIxpyAQEYm5VKULcLSam5t9yZIllS6GiMgJ5Zlnnnnd3VsmW3fCBcGSJUtYt25dpYshInJCMbPth1qnS0MiIjGnIBARiTkFgYhIzJ1wbQSTGRkZoa2tjXw+X+milFU2m6W1tZV0Ol3poojISeSkCIK2tjbq6upYsmQJB04WefJwdzo7O2lra2Pp0qWVLo6InEROiktD+Xye2bNnn7QhAGBmzJ49+6Sv9YjIzDspggA4qUNgVBz+RhGZeSdNEBzRUB/07ATNtioicoD4BMHIAPTthlJx2nfd1dXFV7/61aN+3dVXX01XV9e0l0dE5GiUNQjMbJWZbTazLWZ22yTr/8bMno1+Xozu+1oeyainTWlk2nd9qCAoFAqHfd2aNWtobGyc9vKIiByNsvUaMrMk4abb7wTagLVmttrdN45u4+7/edz2fwJcVK7ykIiCoDgC6dy07vq2225j69atLF++nHQ6TTabpampiRdeeIEXX3yR97znPezYsYN8Ps8nPvEJbr75ZmD/dBl9fX1cddVVvOUtb+FnP/sZCxcu5Ec/+hG53PSWU0RkMuXsProS2OLu2wDM7D7gOmDjIbb/IPAXb/Sgn//nDWzc2XPwCi+Fy0Op3v2hMEXnLKjnL3773EOu/8IXvsDzzz/Ps88+y+OPP84111zD888/P9bN8+6772bWrFkMDg5y6aWXcv311zN79uwD9vHSSy9x77338s1vfpMbbriBH/zgB9x0001HVU4RkWNRzktDC4Ed4563RcsOYmanAEuBfy1baSz6U2egsXjlypUH9PX/yle+woUXXshll13Gjh07eOmllw56zdKlS1m+fDkAl1xyCa+88krZyykiAsfPgLIbgQfcfdKWXDO7GbgZYPHixYfd0eG+ubPrOcg1QeOiYy7oVNTU1Iz9/vjjj/Poo4/y85//nOrqaq644opJxwJUVVWN/Z5MJhkcHCxrGUVERpWzRtAOjD/jtkbLJnMjcO+hduTud7n7Cndf0dIy6XTaU5NMl6WxuK6ujt7e3knXdXd309TURHV1NS+88AJPPfXUtB9fROSNKGeNYC2wzMyWEgLgRuBDEzcys7OAJuDnZSxLkEiHxuJpNnv2bN785jdz3nnnkcvlmDt37ti6VatW8fWvf52zzz6bM888k8suu2zajy8i8kaULQjcvWBmtwAPAUngbnffYGZ3AOvcfXW06Y3Afe4zcPE+mYah8kzR8L3vfW/S5VVVVTz44IOTrhttB2hubub5558fW/6pT31q2ssnInIoZW0jcPc1wJoJyz434fn/Vc4yHCCZhlIhNBhrugYRESBOI4sh6jbqIQxERASIWxAkxw0qExERIK5BUIaeQyIiJ6p4BUFCNQIRkYniFQTJqG1cNQIRkTHxCgJLQCI17TWCY52GGuDLX/4yAwMD01oeEZGjEa8ggLIMKlMQiMiJ7HiZa2jmlGGaifHTUL/zne9kzpw53H///QwNDfHe976Xz3/+8/T393PDDTfQ1tZGsVjks5/9LLt372bnzp1ceeWVNDc389hjj01ruUREpuLkC4IHb4PXfn3o9YV8uEtZpubQ20w073y46guHXD1+GuqHH36YBx54gF/84he4O9deey0//elP6ejoYMGCBfz4xz8GwhxEDQ0NfOlLX+Kxxx6jubl56uUREZlG8bs0ZAaUgPLMaPHwww/z8MMPc9FFF3HxxRfzwgsv8NJLL3H++efzyCOP8OlPf5onn3yShoaGshxfRORonXw1gsN8cwegvwO622DuefvHFUwjd+f222/nox/96EHr1q9fz5o1a/jMZz7D29/+dj73uc9NsgcRkZkVvxpBIhMep7HBePw01L/1W7/F3XffTV9fHwDt7e3s2bOHnTt3Ul1dzU033cStt97K+vXrD3qtiEglnHw1giMpw1iC8dNQX3XVVXzoQx/i8ssvB6C2tpbvfve7bNmyhVtvvZVEIkE6neZrX/saADfffDOrVq1iwYIFaiwWkYqwmZj9eTqtWLHC161bd8CyTZs2cfbZZ09tB8Vh2L0BGhZBzYnXQHtUf6uISMTMnnH3FZOti+GlIU0zISIyXvyCwCyMLtY0EyIiwEkUBEd1iStZnltWltuJdhlPRE4MJ0UQZLNZOjs7p36iLNO9i8vJ3ens7CSbzVa6KCJykjkpeg21trbS1tZGR0fH1F4wsBdGBqHzxPqGnc1maW1trXQxROQkc1IEQTqdZunSpVN/weNfgMf/O3z29bIMKhMROZGcFJeGjlrdvPDYt7uy5RAROQ7ENAjmh8fe1ypbDhGR40BMgyCqEfTuqmw5RESOAzENAtUIRERGlTUIzGyVmW02sy1mdtshtrnBzDaa2QYz+145yzOmuhksqRqBiAhl7DVkZkngTuCdQBuw1sxWu/vGcdssA24H3uzu+8xsTrnKc4BEAjK1MNw/I4cTETmelbNGsBLY4u7b3H0YuA+4bsI2fwTc6e77ANx9TxnLc6B0NowlEBGJuXIGwUJgx7jnbdGy8c4AzjCzfzezp8xs1WQ7MrObzWydma2b8qCxI0lloTA0PfsSETmBVbqxOAUsA64APgh808waJ27k7ne5+wp3X9HS0jJNR85CQTUCEZFyBkE7sGjc89Zo2XhtwGp3H3H3l4EXCcFQfuksjORn5FAiIsezcgbBWmCZmS01swxwI7B6wjb/RKgNYGbNhEtF28pYpv1SOSgoCEREyhYE7l4AbgEeAjYB97v7BjO7w8yujTZ7COg0s43AY8Ct7t5ZrjIdIFWlIBARocyTzrn7GmDNhGWfG/e7A38W/cysdA4G9834YUVEjjeVbiyuHPUaEhEBYh8E6jUkIhLfIFCvIRERIM5BkMrp0pCICLEOgipdGhIRIc5BkM5BcRhKxUqXRESkouIbBKlseNTlIRGJOQWBBpWJSMzFNwjSURBoKmoRibn4BkEqFx5VIxCRmItxEFSFRwWBiMRcfIMgHdUINKhMRGIuvkGgxmIREUBBoEFlIhJ78Q2CsV5DqhGISLzFNwjUa0hEBIh1EKjXkIgIxDkIxnoNqY1AROItvkGguYZERAAFgXoNiUjsxTcIkmmwhHoNiUjsxTcIzKK7lCkIRCTe4hsEEN2lTEEgIvFW1iAws1VmttnMtpjZbZOs/z0z6zCzZ6OfPyxneQ6SzunSkIjEXqpcOzazJHAn8E6gDVhrZqvdfeOETb/v7reUqxyHlcqqRiAisVfOGsFKYIu7b3P3YeA+4LoyHu/oKQhERMoaBAuBHeOet0XLJrrezJ4zswfMbNFkOzKzm81snZmt6+jomL4SprMaUCYisVfpxuJ/Bpa4+wXAI8A9k23k7ne5+wp3X9HS0jJ9R0/lNKBMRGKvnEHQDoz/ht8aLRvj7p3uPnom/hZwSRnLc7BUlQaUiUjslTMI1gLLzGypmWWAG4HV4zcws/njnl4LbCpjeQ6mXkMiIuXrNeTuBTO7BXgISAJ3u/sGM7sDWOfuq4GPm9m1QAHYC/xeucozKTUWi4iULwgA3H0NsGbCss+N+/124PZyluGwFAQiIhVvLK4s9RoSEYl5EKhGICKiIKCQB/dKl0REpGLiHQTpLHgJiiOVLomISMXEOwjGbmCvdgIRia+YB8HoDew1ulhE4iveQaAb2IuIxDwIxu5brJ5DIhJfCgJQEIhIrMU7CNJREGi+IRGJsXgHgXoNiYjEPQhGLw2p15CIxFe8g2Ds0pBqBCISX/EOAjUWi4goCAAFgYjEWryDYGxAmYJAROIr3kEwViNQG4GIxJeCANRrSERibUpBYGafMLN6C75tZuvN7F3lLlzZJRKQzKjXkIjE2lRrBP/J3XuAdwFNwIeBL5StVDMplVNjsYjE2lSDwKLHq4HvuPuGcctObKkqBYGIxNpUg+AZM3uYEAQPmVkdUCpfsWZQOqteQyISa6kpbvcHwHJgm7sPmNks4PfLV6wZlMqp15CIxNpUawSXA5vdvcvMbgI+A3Qf6UVmtsrMNpvZFjO77TDbXW9mbmYrplie6ZOqUq8hEYm1qQbB14ABM7sQ+CSwFfi7w73AzJLAncBVwDnAB83snEm2qwM+ATx9FOWePumceg2JSKxNNQgK7u7AdcD/dvc7gbojvGYlsMXdt7n7MHBf9PqJ/m/gr4DKXKhPZdVYLCKxNtUg6DWz2wndRn9sZgkgfYTXLAR2jHveFi0bY2YXA4vc/ceH25GZ3Wxm68xsXUdHxxSLPEUKAhGJuakGwQeAIcJ4gteAVuCLb+TAUZh8iXCp6bDc/S53X+HuK1paWt7IYQ+mXkMiEnNTCoLo5P/3QIOZvRvIu/th2wiAdmDRuOet0bJRdcB5wONm9gpwGbB6xhuM1WtIRGJuqlNM3AD8Ang/cAPwtJm97wgvWwssM7OlZpYBbgRWj6509253b3b3Je6+BHgKuNbd1x3D33Hs1GtIRGJuquMI/hy41N33AJhZC/Ao8MChXuDuBTO7BXgISAJ3u/sGM7sDWOfuqw/12hmVzunSkIjE2lSDIDEaApFOplCbcPc1wJoJyz53iG2vmGJZplcqq0tDIhJrUw2CfzGzh4B7o+cfYMIJ/oSVykJxGEqlMBupiEjMTCkI3P1WM7seeHO06C53/2H5ijWD0uNuV5mprmxZREQqYKo1Atz9B8APyliWykhFt6tUEIhITB02CMysF/DJVgHu7vVlKdVMSlWFRw0qE5GYOmwQuPuRppE48Y3dwF4NxiIST2odTY1rIxARiSEFgYJARGJOQTDaa0iDykQkphQEY72G1EYgIvGkIBjrNaT5hkQknhQE6jUkIjGnIFBjsYjEnIJAQSAiMacgUK8hEYk5BYF6DYlIzCkIkmnA1GtIRGJLQWAW3aVMNQIRiScFAUR3KVMbgYjEk4IAFAQiEmsKAgg9h9RrSERiSkEAoeeQagQiElMKAgjzDamxWERiSkEAodeQuo+KSEyVNQjMbJWZbTazLWZ22yTr/9jMfm1mz5rZv5nZOeUszyGlshpQJiKxVbYgMLMkcCdwFXAO8MFJTvTfc/fz3X058NfAl8pVnt78CBt39ky+MqXGYhGJr3LWCFYCW9x9m7sPA/cB143fwN3Hn5lrAC9XYf7u59u5+itPMjhcPHhlWt1HRSS+yhkEC4Ed4563RcsOYGYfM7OthBrBxyfbkZndbGbrzGxdR0fHMRVmfkOYXG5n9ySXgDSOQERirOKNxe5+p7ufBnwa+MwhtrnL3Ve4+4qWlpZjOs6CxjC53K6uSU74qax6DYlIbJUzCNqBReOet0bLDuU+4D3lKsyChhAEO7smOeGr15CIxFg5g2AtsMzMlppZBrgRWD1+AzNbNu7pNcBL5SrM3IZwb+LJLw1VhV5DXrYmChGR41aqXDt294KZ3QI8BCSBu919g5ndAaxz99XALWb2DmAE2Ad8pFzlqUolaamrOsSloRx4CYojkMqUqwgiIselsgUBgLuvAdZMWPa5cb9/opzHn2hBQ3byGkF1U3gc6IT6+TNZJBGRiqt4Y/FMmt+Qm7yNoPGU8Nj16swWSETkOBCrIFjQmGNXdx6f2BbQuDg8KghEJIZiFgRZBoaLdA+OHLiiIerc1LV95gslIlJhMQuC0S6kExqMM9VQ06IagYjEUqyCYHR08a7JGowbF6tGICKxFKsg2F8jOESDsWoEIhJDsQqCltoq0kljZ/ckYwkaF0PXDiiVZr5gIiIVFKsgSCSMufVZdk1aI1gMpRHoe23mCyYiUkGxCgIIcw4d1FgMGksgIrEVvyBoPMToYo0lEJGYil0QzG/MsbsnT7E0cVCZxhKISDzFLggWNGQZKTqv902Ydjqdg5o5qhGISOzELwgO24V0MexTjUBE4iV2QTA/ukHNrsm6kDZpLIGIxE/sgmDhkWoE3W1QmuQG9yIiJ6nYBUF9LkV1JnmILqTRWIJejSUQkfiIXRCYGfMbsoeebwh0eUhEYiV2QQChwVg3qBERCeIZBA25yecbamgNjwoCEYmRWAbB/MYsHb1DDBUmNAqnc1A7V4PKRCRWYhkEo2MJdncPHbxS9yUQkZiJZxBEYwkmn3NIYwlEJF5iGQTzG49wpzKNJRCRGClrEJjZKjPbbGZbzOy2Sdb/mZltNLPnzOwnZnZKOcszarRG8HJH/8ErGxdDqQC9u2aiKCIiFVe2IDCzJHAncBVwDvBBMztnwma/BFa4+wXAA8Bfl6s84+UySS5d0sTXntjKj5+bcMLXWAIRiZly1ghWAlvcfZu7DwP3AdeN38DdH3P3gejpU0BrGctzgG995FIubG3kT+5dz/1rd+xfobEEIhIz5QyChcC4Myxt0bJD+QPgwTKW5wANuTR/9wcrefPpzfyXHzzHXT/dirvvH0vQuWWmiiIiUlHHRWOxmd0ErAC+eIj1N5vZOjNb19HRMW3Hrc6k+NZHVnDVefP4yzUv8N6v/oz1uwbhlLfA+u/AyCSNySIiJ5lyBkE7sGjc89Zo2QHM7B3AnwPXuvskHfvB3e9y9xXuvqKlpWVaC1mVSnLnhy7mi++7gJ1dg/zOV3/GV0rvCzexX3f3tB5LROR4VM4gWAssM7OlZpYBbgRWj9/AzC4CvkEIgT1lLMthJRLG+1cs4rFPXcHH33Y6d748j38rnkv3I3/No7/aRqFYqlTRRETKrmxB4O4F4BbgIWATcL+7bzCzO8zs2mizLwK1wD+Y2bNmtvoQu5sRNVUp/uxdZ/Lkp69k18WfpKHUxbr7/4q3/vVjfPnRF3ltsvmJREROcObuR97qOLJixQpft27djByr9N3rKby6jo+1/B8e2TpIMmG87aw5XHvhAt66rJnG6syMlENE5I0ys2fcfcVk61IzXZgTSeLKPyfzzSv55hnr2P47H+PeX+zggWd28MjG3SQMli9q5Ioz53DlmXM4d0E9iYRVusgiIkdNNYIjufdDsOVROOsaOOsaiqe9g1+97jy+uYMnNu/hufZu3KG5toorzmzht86dx2+e0UxVKjlzZRQROYLD1QgUBEfSswse/0vY/CD0d0AiDWe/G970cVh4Ma/3DfHTFzt4bHMHT27eTVe+SH02xarz5rHqvHmcNa+e+Q1ZzFRbEJHKURBMh1IR2tbBxh/BL78DQz2w5K1wznWwZxO0P4Pv3kBX8yV8s+aj3LO1mv7hMHFdTSbJ6XNquezU2bzr3HlctKhRl5FEZEYpCKZbvgfW3wNPfQ162qGqHhYsh+Yz4fkHIN9D4dI/Yv3SP2Zzd4Kte/p44bUentm+j5GiM6euiivPnMOyubWc1hJ+WptyCgcRKRsFQbkUR0IQNCyGRNQTd2Av/OQOeOZvIZmB+vnhrme1cxmqnsdL+Xqeej3Ho3tq+cXgQkpRD97G6jQrTmni0iWzWLFkFufMryeXUTuDiEwPBUEl7HwWfv0P0Lc7/PTuhp6dMNw7tkkp20TXvDfxUt1v8NP8qTy4s4ZtnWFai2TCOL25hsvnFmhumceshjqaazMsaMyxbG6tGqNF5KgoCI4n+e5w45vdG2HbY7DlJ2E6C4BMLcMt59GZmI3t3UrDwHZyPsiQp/mVn8q60pk8VTqbtXYep8+bxfmtDZwxp5alLbWc2lzDgsYcSV1eEpFJKAiOZ+7Q8QK0PwO7fhV+el+D2adB8xkw61SK+16l+MrPSO9+DvMC/akmnqz6D/xt/0q25+tosH4arY95iR7OrelmWdU+FiY68dxsBpvOojTnbDILL2TJ4lOoqdLQEZE4UhCcLIYHQi3iue+H7qzF4Uk367E62kuzaKaLFuseW77TZ7EluYzO+rOoTwzRMryDOcM7yHqe7pYV5M64kpbz34HVNIf2j+IwZKoh2zBTf6GIlImC4GQ02AUv/gsU8pBrCj/Vs6FhEWTrKZWc3nyBns6dDO/8NSPtv8Z2PUtj1wbmjuxgmBTtNp8diYX0F5Nc7BuYa10HHaZoSbbNXcXLp/9HRuZcyILGLKc219JQnYZiAXraYO/L4UY+DQuhdSVk6yvwhojI4SgI5EDD/ZDKQiI0OLs7W/f08dLG9Qy+9FMGB3royhv7hpyFI9t5f/IJai3P06Wz2O1NzLO9LEzsYy6dpCgesGu3BPmmsygsXEntaZdhrZeGy1zF4XAJ7LXnw/2gq2dBdTPUNIMlw32iSwVIpEKg1C+EZLoS745IZXRuhSe/BHPPgYs+PO1fqBQEcsyKJaevZy88cw/Z575DsVigK9XCbmaxvdDEpvxsnhuYRZs3s9j2cGliM5fYi1yU2EKthdla88laMqVBEl48wtHGM6ibD6kMlEohJKrqYOlb4dQrw2NVfbh50HBfGPBXPTtsD6HtpW83vP4SDHRCrjGqOc0K3XlTR5gw0B28NBaWImXjHgapPngblEYvydbBxR+GM6+GfBf07QkzGyx7Fyy8+JgOoyCQssqPFGnvGqRncITB4SIDw0X29PSze+tzWPsztPRuZK/Xsqm0mBd8MTt9No30Mdt6abJeqtMJGmuzNNRU05yFFu+gubCHWcUOalJOdTZDTbaKmuFObPu/w0g/YGAWTtbjZRtDIPR3hNHfk4pCpnFReMzWh1DJ1IRxIR0vwuubYagX6hZA4+KwbXEEBvfB4N5QqxotgyVgzjlw2pVw6hVh+3xP2FfvLqhpgdnLIJ3dXwT3sC+AdDWkqsK+jsbwAOzdFjoXjPSHUBwZhKYlYYBjruno9jelY/bDvldg33bo2h56wNXOgZazYc7Zoaa542nY8VToQj3vfLjgAzD/wv1/X6kYXlvVEGqGo8tHw7tzS/h3TWXDTzIT3uNEMjzmGsO/82TvV74btv8cXnkyfAkoFcCLYX8tZ8Epb4LFbwpl7tsdvoV3bQ/HqWkJNdRSEfZshN0bQi12qA+KQ+EEncyE+5o3LQk11+72sN2eDeHfwZKhVptIgLP/2GM/0fl29unhhL7gInj5Cdj0z2Gmgvd+PZTrqa/Bhh+G8o93zf8Ll/7hMf3TKQikooYLJQqlEgkzEmbkC0V27B1gx94BXt07wM6uPLu6B9nVnef13iHyhRKDw0XyhSITP56NVXBZeiuXJTfRVAXVtQ3UNzRRn6siO9xJZmgvmaG9JGpbyM0/k9z8s7DaOeHEPLgv1A56dkL3jtCu0bsrnPCHemFkIJwMms+EljNC7aGnPWzXtSPUIkbbYzK1oUBeCgHR/sz+bsDpmiisxrNw8qhpDmNK+l47sLHfEuF1mXE/loiCzsNJJZEIJxqzMAdW787Dv/FNS8PJuao+1KYyNaGsw73h5OalcEKsnRsevRTCZXyojAyEk3/XDtj3cjhJjZesCifJiZKZcOLdsyl8y20+ExZeEk6sezZBIboNbKY2vC+pKnh9Cwx1H7yvySQzUDMnhAJRIBSHofOl8Hckq0Kvu1QmnJi9FE7YIwNh21Q2tK8dTiId9pFrCpcpk5lQ7n1RAHox/Hs0nxEu5zQsCscpFcMJ3Gz/v5cloh8L6zo2Q/t6GHg9HOftn4XL/2T/wFQIn9M9m8JnpmbOgTXeY6AgkBNSqeS81pPnlc5+tncOsKs7T1++QN/QCL35Ajv2DfByR//YnE6TyaYTLGjMsaipmkWzwmMukxwLmGTCqMumqM+mqa8yFs2uo6Wu6ugnCXQP/7m3PR5OmHXzoaEV6uaFk+doLWOgE2rnhRHndfPDa0cGohPwQLjMNdwfftz3n0QgnGBGv2HWzoNZp8LsU6G+Nc5agxMAAAwSSURBVAqP6nCy6twSTjI7fxl+H+rbf/JPVYWTb1UtYOGSw2Qn37FgqoZ0Lhxj1pJwzKYl4afxlHByGty3/wQ/3A+LVsL85aEGNLAXNv4T/Or7sHdrCKa550PLmftrF13bQ+g0LwuBMfu06KQ7FE7WxaHoUp2Hk+jg3lDuvj2hBjBWZgs1s6VvhdZLQ7nHK46E7tnb/z28tmnc31MYCrXIgdfDceaeG761H6qdqlgI/641zeE9PRbuIVASSahfcGz7OAoKAjlpuTt7eofY3ZOnWHJKHto1OvuG2NmdZ1fXIO1dg+zYN8CrnQP05AtH3GddVYpT59SyqClHTSZFdVWSmkxqbGT3gsYczbVVpJJGKmEkE0ZNJnXizhU1MhhOgpaMTvxRoGjG3JOKbkwjJy0zY259lrn12SNvDPTkRxgplMZeWyiW6MkX6MmP0D04wqudA2zt6GNrRx/Pt3czMFwM7R4jRYqlQ39pSieNltoqWuqzzKuvorWpmkVNORY2VVMdzRllQFU6wZy6UN5Mqpy3DD8K6Vxo15DYUhBIrNRnD67qz5lCLz13p7N/mJ1dg+zsyrO3f5hiqUSh5IwUS+wbGGF3T56O3iG2dvTzxIsd5EdKh91nc22GqlSSRAKSZlSlksyuzTC7toqW2ioWzcqxtLmG01pqmVNfRbHkjBSdYslpyKU1nYhMGwWByBSYGc21VTTXVnFB65G3Hw2O9n2DDEU1EHdncKTI7p48r3UP8VpPnuFCCXenFK3r7Bvm121ddPQOHbbtI5Ww0PYxK8ecuiyphEWXqhLUVKVoyKVprE4zqyZDa1OO1qZqGnIalyGTUxCIlMH44DgW7s7rfcNs6+hj2+v9vN47RDqVIJ1MkDTo6Bvi1b2D7Ng7wNrOvZRKTiH66c2PMFI8+DJWXTbF/IZwWWpefZbmuirqsinqqlLURg3mjdVpGnJp6rNpcpkkuXSSVPI4uYQlZaMgEDkOmRktdVW01FXxG6fOPqrXjtY8ugdH6Ogdon3fIG37BmnbF3pe7e7J8+LuXjr7hikcpt1jVCaZIJtOjAVDfS7NolnVnDKrmsWzqsmkEpQ89PJKJoxZNRmaajI0VadJjwuR6kySxupj7/4o5aMgEDnJmBnVmRTVmRTzG3Jc0No46XbuzlChRG++QG9+hJ58ga6BYboHw+/54SKDI2GAYH6kODa2Y2//MBvau3no+demFCTjNVWnOa2lllNbamipq6Ixl6GhOk11Jhn1+nLcoak6w7yGUHNprE7rnt9lpiAQiSkzI5tOkk0naak7+ktYhWKJ13ryFIqhJmAGhaKzb2CYfQPD7O0foVja32Demy+wtaOfrR19PLa5I2pwP3KQhO65SWqrUge0f9TnwmWs0eU1mSQDw0X2DYzQNTDMQNTGYhYa4xfNqubs+fWcu6Ce1qacwmWcsgaBma0C/ieQBL7l7l+YsP43gS8DFwA3uvsD5SyPiEyfVDJBa1P1QcuXUDOl17s7fUMFugZGGBwpkrAwJsOAzv5hdvfk2dWdp7NviIHhIn1DBfqirr47u/Js2tVL9+AI/cOFA0agp5NGY3WGmqjbrhMC6ofPto9tl00nQrfjuixz6qtCoETtJblMikwqQSZqfC+WnKFCcazRvz6bpj4X2lTmNWRZ0Jgjmz6x56QqWxCYWRK4E3gn0AasNbPV7r5x3GavAr8HfKpc5RCR45OZUZdNUzdJl94lzVMLEwhtE4MjRfqHC2EAYCY56bf9weEim3f3snFnD9s6+sYGIm7Y2UPP4Ah9Q4Wxk/3Rmltfxdz6LLl0klwmSXUmSTaVJJNKUDXayJ8wEgkjnTCaajLR+JcqZtVUhddFr63E+JJy1ghWAlvcfRuAmd0HXAeMBYG7vxKtO7Z3X0RiL5GwcGnoCHffy2WSLF/UyPJFk7eZQJgXa3CkyHChxEgx/KSS4WSeSSVwJ7SnDBboGhxmV1d+rCG+o2+IweHQhtK2L+xjtCYxXCiNtYFM1qNrvHTSxi53ZdNJPGo3ceBP37GM65YvPJa36bDKGQQLgR3jnrcBv3EsOzKzm4GbARYv1ghIESmPTHTCP5yGXBrewMSupZLTNRgGIO7uybNvYJjB4RBAg8MF+oaK9A8V6B+toVgYlW5mzK45xnmNjuCEaCx297uAuyDMNVTh4oiIHLNE1MV2Vk2Gs+cfH3fzK+fFqHZg0bjnrdEyERE5jpQzCNYCy8xsqZllgBuB1WU8noiIHIOyBYG7F4BbgIeATcD97r7BzO4ws2sBzOxSM2sD3g98w8w2lKs8IiIyubK2Ebj7GmDNhGWfG/f7WsIlIxERqRDNJiUiEnMKAhGRmFMQiIjEnIJARCTmTrib15tZB7D9GF/eDLw+jcU5Weh9mZzel8npfZnc8f6+nOLuLZOtOOGC4I0ws3XuvqLS5Tje6H2ZnN6Xyel9mdyJ/L7o0pCISMwpCEREYi5uQXBXpQtwnNL7Mjm9L5PT+zK5E/Z9iVUbgYiIHCxuNQIREZlAQSAiEnOxCQIzW2Vmm81si5ndVunyVIqZLTKzx8xso5ltMLNPRMtnmdkjZvZS9PgG7sF0YjKzpJn90sz+v+j5UjN7OvrMfD+aTj12zKzRzB4wsxfMbJOZXa7PC5jZf47+Dz1vZveaWfZE/czEIgjMLAncCVwFnAN80MzOqWypKqYAfNLdzwEuAz4WvRe3AT9x92XAT6LncfMJwpTpo/4K+Bt3Px3YB/xBRUpVef8T+Bd3Pwu4kPAexfrzYmYLgY8DK9z9PCBJuOfKCfmZiUUQACuBLe6+zd2HgfuA6ypcpopw913uvj76vZfwn3oh4f24J9rsHuA9lSlhZZhZK3AN8K3ouQFvAx6INondewJgZg3AbwLfBnD3YXfvIuafl0gKyJlZCqgGdnGCfmbiEgQLgR3jnrdFy2LNzJYAFwFPA3PdfVe06jVgboWKVSlfBv4LUIqezwa6ohssQXw/M0uBDuD/RJfNvmVmNcT88+Lu7cD/AF4lBEA38Awn6GcmLkEgE5hZLfAD4E/dvWf8Og99imPTr9jM3g3scfdnKl2W41AKuBj4mrtfBPQz4TJQ3D4vAFGbyHWEoFwA1ACrKlqoNyAuQdAOLBr3vDVaFktmliaEwN+7+z9Gi3eb2fxo/XxgT6XKVwFvBq41s1cIlw3fRrgu3hhV+yG+n5k2oM3dn46eP0AIhjh/XgDeAbzs7h3uPgL8I+FzdEJ+ZuISBGuBZVGLfobQqLO6wmWqiOja97eBTe7+pXGrVgMfiX7/CPCjmS5bpbj77e7e6u5LCJ+Nf3X33wUeA94XbRar92SUu78G7DCzM6NFbwc2EuPPS+RV4DIzq47+T42+LyfkZyY2I4vN7GrCdeAkcLe7/7cKF6kizOwtwJPAr9l/Pfy/EtoJ7gcWE6b5vsHd91akkBVkZlcAn3L3d5vZqYQawizgl8BN7j5UyfJVgpktJzSiZ4BtwO8TvkTG+vNiZp8HPkDoifdL4A8JbQIn3GcmNkEgIiKTi8ulIREROQQFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIjMIDO7YnR2U5HjhYJARCTmFAQikzCzm8zsF2b2rJl9I7pXQZ+Z/U00B/1PzKwl2na5mT1lZs+Z2Q9H5+Y3s9PN7FEz+5WZrTez06Ld146b3//vo5GpIhWjIBCZwMzOJowYfbO7LweKwO8SJhZb5+7nAk8AfxG95O+AT7v7BYQR26PL/x64090vBN5EmKUSwoyvf0q4N8aphDlqRComdeRNRGLn7cAlwNroy3qOMKlaCfh+tM13gX+M5utvdPcnouX3AP9gZnXAQnf/IYC75wGi/f3C3dui588CS4B/K/+fJTI5BYHIwQy4x91vP2Ch2WcnbHes87OMn3umiP4fSoXp0pDIwX4CvM/M5sDY/ZxPIfx/GZ1Z8kPAv7l7N7DPzN4aLf8w8ER097c2M3tPtI8qM6ue0b9CZIr0TURkAnffaGafAR42swQwAnyMcFOWldG6PYR2BAjTDX89OtGPzs4JIRS+YWZ3RPt4/wz+GSJTptlHRabIzPrcvbbS5RCZbro0JCISc6oRiIjEnGoEIiIxpyAQEYk5BYGISMwpCEREYk5BICISc/8/5+8ZRYor1dAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZkGJtk6pRcu"
      },
      "source": [
        "model2 = keras.models.load_model('/content/drive/MyDrive/model-0.21-dessed.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jAOtu-FvhlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc16a20c-669e-46b9-acce-8784e265458b"
      },
      "source": [
        "TP = 0\r\n",
        "FP = 0\r\n",
        "TN = 0\r\n",
        "FN = 0\r\n",
        "\r\n",
        "y_pred = model.predict(x_test, batch_size=8, verbose=1)\r\n",
        "\r\n",
        "for i in range(y_test.shape[0]):\r\n",
        "    if i%100 == 0:\r\n",
        "        print(\"processing element \", i)\r\n",
        "    for j in range(y_test.shape[1]):\r\n",
        "        for k in range(y_test.shape[2]):\r\n",
        "            \r\n",
        "            test = y_test[i][j][k]\r\n",
        "            pred = y_pred[i][j][k]\r\n",
        "            \r\n",
        "            # binarization of predicted output\r\n",
        "            if(pred >= 0.5):\r\n",
        "                pred = 1\r\n",
        "            else:\r\n",
        "                pred = 0\r\n",
        "\r\n",
        "            if(test == 1 and pred == 1):\r\n",
        "                TP = TP + 1\r\n",
        "            elif(test == 0 and pred == 1):\r\n",
        "                FP = FP + 1\r\n",
        "            elif(test == 0 and pred == 0):\r\n",
        "                TN = TN + 1\r\n",
        "            elif(test == 1 and pred == 0):\r\n",
        "                FN = FN + 1\r\n",
        "                \r\n",
        "#print(TP+FP+TN+FN)\r\n",
        "#print(y_test.shape[1]*y_test.shape[2]*y_test.shape[0])\r\n",
        "\r\n",
        "recall = TP/(TP+FN)\r\n",
        "\r\n",
        "precision = TP/(TP+FP)\r\n",
        "\r\n",
        "f1_score = 2*recall*precision/(recall+precision)\r\n",
        "\r\n",
        "print(\"recall: \", recall)\r\n",
        "print(\"precision: \", precision)\r\n",
        "print(\"f1: \", f1_score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85/85 [==============================] - 4s 44ms/step\n",
            "processing element  0\n",
            "processing element  100\n",
            "processing element  200\n",
            "processing element  300\n",
            "processing element  400\n",
            "processing element  500\n",
            "processing element  600\n",
            "recall:  0.5580331482323775\n",
            "precision:  0.7318318205132828\n",
            "f1:  0.6332235151324377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvaDrIHpvhnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b184ff-c819-4528-d7c5-382dfa7b114a"
      },
      "source": [
        "TP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTAioOcvhpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0efd741-5b20-4714-86e1-52dd169cddc3"
      },
      "source": [
        "print(\"f1: \", f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1:  0.335704965485368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0V-hVJgdEmg"
      },
      "source": [
        "## save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebi1aSfc7zr"
      },
      "source": [
        "filename = '/content/drive/MyDrive/model-dessed-endtrain.h5'\r\n",
        "model.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}