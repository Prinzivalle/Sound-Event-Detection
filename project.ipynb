{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "challenging-orientation",
   "metadata": {},
   "source": [
    "# add title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-message",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.1\n",
      "Keras version 2.4.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"Tensorflow version %s\" %tf.__version__)\n",
    "print(\"Keras version %s\" %keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-minnesota",
   "metadata": {},
   "source": [
    "## Load data and get mel spectrogram from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "    \n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '/Xception/UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"]),str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-handbook",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "threaded-differential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.3752213e+01, -7.1893913e+01, -7.4429947e+01, ...,\n",
       "        -9.7842186e+01, -9.4238541e+01,  0.0000000e+00],\n",
       "       [ 1.1466684e+02,  1.1912703e+02,  1.2508240e+02, ...,\n",
       "         1.1245096e+02,  1.0646953e+02,  0.0000000e+00],\n",
       "       [-7.3170403e+01, -8.1585869e+01, -8.7429298e+01, ...,\n",
       "        -1.0017877e+02, -1.0056201e+02,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 6.2128234e-01, -1.4668137e-02,  9.3862867e-01, ...,\n",
       "         5.4531813e-01,  3.0852802e+00,  0.0000000e+00],\n",
       "       [ 3.8533199e+00,  1.1004624e+00,  1.5143282e+00, ...,\n",
       "         4.1922727e+00,  4.5371199e+00,  0.0000000e+00],\n",
       "       [ 3.2343304e+00, -2.4159760e+00, -1.5217065e+00, ...,\n",
       "        -1.3523768e+01, -1.0443431e+01,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf.feature[0]\n",
    "features\n",
    "x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-input",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-technician",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 7.2314 - accuracy: 0.1243\n",
      "Pre-training accuracy: 11.6772%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-builder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-oxide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rising-water",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infrared-mounting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 44, 178, 1)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 40, 174, 256)      537       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 40, 174, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 40, 174, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 44, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 40, 34, 256)       72192     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 34, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 44, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 40, 8, 256)        72192     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 40, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 40, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 38, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 38, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 38, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 233472)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2334730   \n",
      "=================================================================\n",
      "Total params: 3,073,827\n",
      "Trainable params: 3,071,779\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "\n",
    "def Net(input_shape, num_classes, dilated_kernel, dilation, dilated_padding):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    #model.add(Input(shape=(256,256,1)))#TODO ADD REAL SIZE\n",
    "    model.add(Input(shape=(num_rows, num_columns, num_channels)))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    model.add(ZeroPadding2D(padding=(2)))\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    model.add(SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    model.add(ZeroPadding2D(padding=(2, 2)))\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    model.add(SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    model.add(ZeroPadding2D(padding=(2, 2)))\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    model.add(SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # DIL-CNN \n",
    "    model.add(ZeroPadding2D(padding=(0, dilated_padding*dilation)))\n",
    "    model.add(Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(1,dilation)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # classifier layer\n",
    "    model.add(Flatten())\n",
    "    #model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "    model.add(Dense(num_labels))\n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "input_shape = (16, 16, 16, 1)\n",
    "num_classes = 16\n",
    "dilated_kernel = (3,3)\n",
    "dilation = (10)\n",
    "dilated_padding = 2\n",
    "model = Net(input_shape,num_classes,dilated_kernel,dilation,dilated_padding)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-musician",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dietary-diploma",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "28/28 [==============================] - 11s 381ms/step - loss: 4.8339 - accuracy: 0.1649 - val_loss: 2.2901 - val_accuracy: 0.1660\n",
      "Epoch 2/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 2.0458 - accuracy: 0.2772 - val_loss: 2.0150 - val_accuracy: 0.3314\n",
      "Epoch 3/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.7436 - accuracy: 0.3898 - val_loss: 1.8234 - val_accuracy: 0.3801\n",
      "Epoch 4/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.5402 - accuracy: 0.4653 - val_loss: 1.6884 - val_accuracy: 0.4396\n",
      "Epoch 5/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 1.4180 - accuracy: 0.5001 - val_loss: 1.6167 - val_accuracy: 0.4768\n",
      "Epoch 6/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.3228 - accuracy: 0.5383 - val_loss: 1.4871 - val_accuracy: 0.5112\n",
      "Epoch 7/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 1.2487 - accuracy: 0.5635 - val_loss: 1.4039 - val_accuracy: 0.5415\n",
      "Epoch 8/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.1934 - accuracy: 0.5824 - val_loss: 1.3463 - val_accuracy: 0.5633\n",
      "Epoch 9/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.1386 - accuracy: 0.6046 - val_loss: 1.2816 - val_accuracy: 0.5799\n",
      "Epoch 10/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 1.0975 - accuracy: 0.6156 - val_loss: 1.2025 - val_accuracy: 0.6199\n",
      "Epoch 11/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 1.0401 - accuracy: 0.6412 - val_loss: 1.1640 - val_accuracy: 0.6325\n",
      "Epoch 12/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.9798 - accuracy: 0.6660 - val_loss: 1.0774 - val_accuracy: 0.6720\n",
      "Epoch 13/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.9888 - accuracy: 0.6561 - val_loss: 1.0977 - val_accuracy: 0.6531\n",
      "Epoch 14/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.9350 - accuracy: 0.6806 - val_loss: 1.0188 - val_accuracy: 0.6795\n",
      "Epoch 15/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.9124 - accuracy: 0.6869 - val_loss: 1.0105 - val_accuracy: 0.6737\n",
      "Epoch 16/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.8664 - accuracy: 0.7061 - val_loss: 0.9404 - val_accuracy: 0.6949\n",
      "Epoch 17/72\n",
      "28/28 [==============================] - 10s 339ms/step - loss: 0.8363 - accuracy: 0.7151 - val_loss: 0.9394 - val_accuracy: 0.6898\n",
      "Epoch 18/72\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.8264 - accuracy: 0.7214 - val_loss: 0.9116 - val_accuracy: 0.7018\n",
      "Epoch 19/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.7901 - accuracy: 0.7291 - val_loss: 0.8583 - val_accuracy: 0.7235\n",
      "Epoch 20/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.7757 - accuracy: 0.7354 - val_loss: 0.8175 - val_accuracy: 0.7407\n",
      "Epoch 21/72\n",
      "28/28 [==============================] - 9s 339ms/step - loss: 0.7336 - accuracy: 0.7516 - val_loss: 0.8376 - val_accuracy: 0.7201\n",
      "Epoch 22/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.7111 - accuracy: 0.7618 - val_loss: 0.7841 - val_accuracy: 0.7447\n",
      "Epoch 23/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.7004 - accuracy: 0.7659 - val_loss: 0.7684 - val_accuracy: 0.7441\n",
      "Epoch 24/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.6813 - accuracy: 0.7701 - val_loss: 0.7146 - val_accuracy: 0.7699\n",
      "Epoch 25/72\n",
      "28/28 [==============================] - 10s 341ms/step - loss: 0.6569 - accuracy: 0.7811 - val_loss: 0.7096 - val_accuracy: 0.7653\n",
      "Epoch 26/72\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.6292 - accuracy: 0.7906 - val_loss: 0.7093 - val_accuracy: 0.7676\n",
      "Epoch 27/72\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.6261 - accuracy: 0.7890 - val_loss: 0.6613 - val_accuracy: 0.7882\n",
      "Epoch 28/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.6229 - accuracy: 0.7928 - val_loss: 0.6387 - val_accuracy: 0.7951\n",
      "Epoch 29/72\n",
      "28/28 [==============================] - 10s 345ms/step - loss: 0.6046 - accuracy: 0.7926 - val_loss: 0.6116 - val_accuracy: 0.8111\n",
      "Epoch 30/72\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.5871 - accuracy: 0.8046 - val_loss: 0.6155 - val_accuracy: 0.7979\n",
      "Epoch 31/72\n",
      "28/28 [==============================] - 10s 343ms/step - loss: 0.5660 - accuracy: 0.8110 - val_loss: 0.6302 - val_accuracy: 0.7928\n",
      "Epoch 32/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.5583 - accuracy: 0.8123 - val_loss: 0.5982 - val_accuracy: 0.8111\n",
      "Epoch 33/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.5362 - accuracy: 0.8209 - val_loss: 0.5691 - val_accuracy: 0.8197\n",
      "Epoch 34/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.5174 - accuracy: 0.8288 - val_loss: 0.5470 - val_accuracy: 0.8288\n",
      "Epoch 35/72\n",
      "28/28 [==============================] - 10s 345ms/step - loss: 0.5099 - accuracy: 0.8305 - val_loss: 0.5243 - val_accuracy: 0.8300\n",
      "Epoch 36/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.4999 - accuracy: 0.8338 - val_loss: 0.5629 - val_accuracy: 0.8231\n",
      "Epoch 37/72\n",
      "28/28 [==============================] - 9s 338ms/step - loss: 0.4792 - accuracy: 0.8375 - val_loss: 0.5116 - val_accuracy: 0.8397\n",
      "Epoch 38/72\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.4718 - accuracy: 0.8361 - val_loss: 0.4956 - val_accuracy: 0.8432\n",
      "Epoch 39/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.4678 - accuracy: 0.8431 - val_loss: 0.5532 - val_accuracy: 0.8248\n",
      "Epoch 40/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.4594 - accuracy: 0.8432 - val_loss: 0.4912 - val_accuracy: 0.8437\n",
      "Epoch 41/72\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.4436 - accuracy: 0.8484 - val_loss: 0.4698 - val_accuracy: 0.8540\n",
      "Epoch 42/72\n",
      "28/28 [==============================] - 10s 348ms/step - loss: 0.4312 - accuracy: 0.8576 - val_loss: 0.4772 - val_accuracy: 0.8454\n",
      "Epoch 43/72\n",
      "28/28 [==============================] - 10s 347ms/step - loss: 0.4250 - accuracy: 0.8558 - val_loss: 0.4851 - val_accuracy: 0.8477\n",
      "Epoch 44/72\n",
      "28/28 [==============================] - 10s 344ms/step - loss: 0.4334 - accuracy: 0.8500 - val_loss: 0.4607 - val_accuracy: 0.8517\n",
      "Epoch 45/72\n",
      "28/28 [==============================] - 10s 352ms/step - loss: 0.4368 - accuracy: 0.8513 - val_loss: 0.4854 - val_accuracy: 0.8472\n",
      "Epoch 46/72\n",
      "28/28 [==============================] - 10s 349ms/step - loss: 0.4207 - accuracy: 0.8578 - val_loss: 0.4631 - val_accuracy: 0.8483\n",
      "Epoch 47/72\n",
      "28/28 [==============================] - 10s 345ms/step - loss: 0.4003 - accuracy: 0.8634 - val_loss: 0.4588 - val_accuracy: 0.8558\n",
      "Epoch 48/72\n",
      "28/28 [==============================] - 10s 340ms/step - loss: 0.4024 - accuracy: 0.8643 - val_loss: 0.4890 - val_accuracy: 0.8449\n",
      "Epoch 49/72\n",
      "28/28 [==============================] - 10s 346ms/step - loss: 0.3807 - accuracy: 0.8704 - val_loss: 0.4183 - val_accuracy: 0.8672\n",
      "Epoch 50/72\n",
      "28/28 [==============================] - 10s 351ms/step - loss: 0.3903 - accuracy: 0.8683 - val_loss: 0.4299 - val_accuracy: 0.8666\n",
      "Epoch 51/72\n",
      "21/28 [=====================>........] - ETA: 2s - loss: 0.3552 - accuracy: 0.8789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4564d05fd921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\hello-tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "#checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "#                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=train_generator.n//train_generator.batch_size\n",
    "val_steps=test_generator.n//test_generator.batch_size+1\n",
    "epochs = 1\n",
    "history = model.fit(train_generator, epochs=epochs, verbose=1,\\\n",
    "                steps_per_epoch=steps_per_epoch,\\\n",
    "                validation_data=test_generator,\\\n",
    "                validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-pollution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-foster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-photographer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
