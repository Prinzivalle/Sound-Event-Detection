{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-origin",
   "metadata": {},
   "source": [
    "# Add title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-literature",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "female-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'plaidml.keras.backend' from 'E:\\\\anaconda3\\\\envs\\\\plaidML\\\\lib\\\\site-packages\\\\plaidml\\\\keras\\\\backend.py'>\n",
      "Keras version 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plaidml.keras\n",
    "import os\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from keras import backend as K\n",
    "print(K)\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"Keras version %s\" %keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-procurement",
   "metadata": {},
   "source": [
    "## Load data and get mel spectrogram from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "directed-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\plaidML\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\envs\\plaidML\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\envs\\plaidML\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "    \n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '/Xception/UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"]),str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-directory",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "illegal-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_gfx1010.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 174, 1)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 44, 178, 1)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 40, 174, 256)      537       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 174, 256)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 44, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 40, 34, 256)       72192     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 44, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 40, 8, 256)        72192     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 40, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 40, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 38, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 38, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 737,571\n",
      "Trainable params: 737,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "\n",
    "def Net(input_shape, num_classes, dilated_kernel, dilation, dilated_padding):\n",
    "    \n",
    "    # input layer\n",
    "    inputs = Input(shape=(num_rows, num_columns, num_channels))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    x = ZeroPadding2D(padding=(2))(inputs)\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    #x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    #x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before since it has a special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    #x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DIL-CNN \n",
    "    x = ZeroPadding2D(padding=(0, dilated_padding*dilation))(x)\n",
    "    x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(1,dilation))(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # classifier layer\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    outputs = Dense(num_labels,activation='sigmoid')(x)\n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model = Model(inputs, outputs)                            \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "input_shape = (256, 256, 1)\n",
    "num_classes = 10\n",
    "dilated_kernel = (3,3)\n",
    "dilation = (10)\n",
    "dilated_padding = 2\n",
    "model = Net(input_shape,num_classes,dilated_kernel,dilation,dilated_padding)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-precipitation",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hydraulic-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5937 samples, validate on 1048 samples\n",
      "Epoch 1/50\n",
      "5937/5937 [==============================] - 59s 10ms/step - loss: 1.7619 - acc: 0.3434 - val_loss: 1.7154 - val_acc: 0.3702\n",
      "Epoch 2/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.6942 - acc: 0.3662 - val_loss: 1.6662 - val_acc: 0.3779\n",
      "Epoch 3/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.6470 - acc: 0.3925 - val_loss: 1.6452 - val_acc: 0.4198\n",
      "Epoch 4/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.5973 - acc: 0.4069 - val_loss: 1.6218 - val_acc: 0.3969\n",
      "Epoch 5/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.5646 - acc: 0.4295 - val_loss: 1.6105 - val_acc: 0.4294\n",
      "Epoch 6/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.5239 - acc: 0.4426 - val_loss: 1.5407 - val_acc: 0.4437\n",
      "Epoch 7/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.4961 - acc: 0.4416 - val_loss: 1.5719 - val_acc: 0.4208\n",
      "Epoch 8/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.4601 - acc: 0.4561 - val_loss: 1.4923 - val_acc: 0.4485\n",
      "Epoch 9/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.4317 - acc: 0.4677 - val_loss: 1.4540 - val_acc: 0.4647\n",
      "Epoch 10/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.4009 - acc: 0.4762 - val_loss: 1.4601 - val_acc: 0.4437\n",
      "Epoch 11/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.3713 - acc: 0.4886 - val_loss: 1.4084 - val_acc: 0.4752\n",
      "Epoch 12/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.3403 - acc: 0.4962 - val_loss: 1.3489 - val_acc: 0.4962\n",
      "Epoch 13/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.3180 - acc: 0.5063 - val_loss: 1.3232 - val_acc: 0.5105\n",
      "Epoch 14/50\n",
      "5937/5937 [==============================] - 27s 4ms/step - loss: 1.2687 - acc: 0.5252 - val_loss: 1.3186 - val_acc: 0.5048\n",
      "Epoch 15/50\n",
      "5937/5937 [==============================] - 23s 4ms/step - loss: 1.2360 - acc: 0.5427 - val_loss: 1.2908 - val_acc: 0.5344\n",
      "Epoch 16/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.2019 - acc: 0.5595 - val_loss: 1.2376 - val_acc: 0.5716\n",
      "Epoch 17/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.1735 - acc: 0.5703 - val_loss: 1.1986 - val_acc: 0.5601\n",
      "Epoch 18/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.1357 - acc: 0.5964 - val_loss: 1.1509 - val_acc: 0.5897\n",
      "Epoch 19/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.1127 - acc: 0.6017 - val_loss: 1.1316 - val_acc: 0.6069\n",
      "Epoch 20/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0893 - acc: 0.6193 - val_loss: 1.1635 - val_acc: 0.5792\n",
      "Epoch 21/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0750 - acc: 0.6183 - val_loss: 1.3440 - val_acc: 0.5248\n",
      "Epoch 22/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0633 - acc: 0.6222 - val_loss: 1.0817 - val_acc: 0.6135\n",
      "Epoch 23/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0363 - acc: 0.6337 - val_loss: 1.0850 - val_acc: 0.6183\n",
      "Epoch 24/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0248 - acc: 0.6454 - val_loss: 1.0751 - val_acc: 0.6393\n",
      "Epoch 25/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 1.0263 - acc: 0.6390 - val_loss: 1.1098 - val_acc: 0.6145\n",
      "Epoch 26/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9980 - acc: 0.6522 - val_loss: 1.0326 - val_acc: 0.6365\n",
      "Epoch 27/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9813 - acc: 0.6569 - val_loss: 1.0231 - val_acc: 0.6603\n",
      "Epoch 28/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9792 - acc: 0.6645 - val_loss: 1.0539 - val_acc: 0.6269\n",
      "Epoch 29/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9644 - acc: 0.6645 - val_loss: 1.1678 - val_acc: 0.5849\n",
      "Epoch 30/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9523 - acc: 0.6710 - val_loss: 1.0256 - val_acc: 0.6326\n",
      "Epoch 31/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9441 - acc: 0.6685 - val_loss: 1.0319 - val_acc: 0.6450\n",
      "Epoch 32/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9349 - acc: 0.6724 - val_loss: 1.0495 - val_acc: 0.6193\n",
      "Epoch 33/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9245 - acc: 0.6817 - val_loss: 1.0173 - val_acc: 0.6355\n",
      "Epoch 34/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.9082 - acc: 0.6823 - val_loss: 0.9260 - val_acc: 0.6937\n",
      "Epoch 35/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8959 - acc: 0.6879 - val_loss: 0.9295 - val_acc: 0.6794\n",
      "Epoch 36/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8933 - acc: 0.6882 - val_loss: 0.9472 - val_acc: 0.6765\n",
      "Epoch 37/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8839 - acc: 0.6926 - val_loss: 1.0736 - val_acc: 0.6040\n",
      "Epoch 38/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8772 - acc: 0.6973 - val_loss: 0.8969 - val_acc: 0.6765\n",
      "Epoch 39/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8666 - acc: 0.6938 - val_loss: 0.9803 - val_acc: 0.6641\n",
      "Epoch 40/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8531 - acc: 0.7024 - val_loss: 0.9195 - val_acc: 0.6689\n",
      "Epoch 41/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8460 - acc: 0.7091 - val_loss: 0.9453 - val_acc: 0.6641\n",
      "Epoch 42/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8407 - acc: 0.7094 - val_loss: 0.9230 - val_acc: 0.6670\n",
      "Epoch 43/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8376 - acc: 0.7074 - val_loss: 0.9530 - val_acc: 0.6489\n",
      "Epoch 44/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8259 - acc: 0.7143 - val_loss: 0.9262 - val_acc: 0.6698\n",
      "Epoch 45/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8237 - acc: 0.7115 - val_loss: 0.8743 - val_acc: 0.6870\n",
      "Epoch 46/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8069 - acc: 0.7192 - val_loss: 0.9175 - val_acc: 0.6527\n",
      "Epoch 47/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.8110 - acc: 0.7243 - val_loss: 0.8924 - val_acc: 0.6803\n",
      "Epoch 48/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.7957 - acc: 0.7236 - val_loss: 0.8681 - val_acc: 0.6823\n",
      "Epoch 49/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.7944 - acc: 0.7217 - val_loss: 0.8989 - val_acc: 0.6823\n",
      "Epoch 50/50\n",
      "5937/5937 [==============================] - 22s 4ms/step - loss: 0.7783 - acc: 0.7285 - val_loss: 0.8397 - val_acc: 0.7223\n",
      "Training completed in time:  0:18:46.850180\n"
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 50\n",
    "num_batch_size = 16\n",
    "\n",
    "#checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "#                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "#history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_split=0.15, verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-coffee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-middle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "shaped-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "1747/1747 [==============================] - 1s 830us/step\n",
      "test loss, test acc: [0.8613504420008465, 0.7126502575844305]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=num_batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-thread",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-conclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-correction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
