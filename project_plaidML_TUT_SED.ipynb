{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-origin",
   "metadata": {},
   "source": [
    "# Sound Event Detection with Depthwise Separable and Dilated Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-literature",
   "metadata": {},
   "source": [
    "## 1 Import major libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "female-coffee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'plaidml.keras.backend' from 'E:\\\\anaconda3\\\\envs\\\\plaidML\\\\lib\\\\site-packages\\\\plaidml\\\\keras\\\\backend.py'>\n",
      "Keras version 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plaidml.keras\n",
    "import os\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from keras import backend as K\n",
    "print(K)\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"Keras version %s\" %keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-diabetes",
   "metadata": {},
   "source": [
    "## 2 Load meta file (onset, offset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "heard-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "meta = pd.read_csv('E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\meta.txt', delimiter = \"\\t\", header=None)\n",
    "meta.columns = [\"file\", \"drop1\", \"onset\", \"offset\", \"label\", \"drop2\"]\n",
    "# delete not useful columns\n",
    "meta = meta.drop(columns=[\"drop1\", \"drop2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-cabin",
   "metadata": {},
   "source": [
    "## 3 Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-mixture",
   "metadata": {},
   "source": [
    "### Labels distribution in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "demanding-genre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "footsteps            8302\n",
       "horsewalk            6603\n",
       "bird_singing         6079\n",
       "baby_crying          3342\n",
       "dog_barking          3145\n",
       "gun_shot             1581\n",
       "crowd_applause       1400\n",
       "cat_meowing           885\n",
       "motorcycle            824\n",
       "thunder               774\n",
       "glass_smash           693\n",
       "crowd_cheering        613\n",
       "alarms_and_sirens     571\n",
       "mixer                 547\n",
       "rain                  511\n",
       "bus                   456\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "meta['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-landing",
   "metadata": {},
   "source": [
    "### Audio properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "explicit-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import re\n",
    "\n",
    "directory = 'E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\audio\\\\'\n",
    "\n",
    "# support to read file header and return audio properties\n",
    "def read_header(filename):\n",
    "    wave = open(filename,\"rb\")\n",
    "    riff = wave.read(12)\n",
    "    fmat = wave.read(36)\n",
    "    num_channels_string = fmat[10:12]\n",
    "    num_channels = struct.unpack('<H', num_channels_string)[0]\n",
    "    sample_rate_string = fmat[12:16]\n",
    "    sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n",
    "    bit_depth_string = fmat[22:24]\n",
    "    bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n",
    "    return (num_channels, sample_rate, bit_depth)\n",
    "\n",
    "# Read every file header to collect audio properties\n",
    "audiodata = []\n",
    "for index, row in meta.iterrows():\n",
    "    cat = str(row[\"label\"])\n",
    "    name = str(row[\"file\"])\n",
    "    i = name[:-4]\n",
    "    i = i[33:]\n",
    "    file_name = directory+'TUT-SED-synthetic-2016-mix-'+str(i)+'.wav'\n",
    "    audio_props = read_header(file_name)\n",
    "    duration = row['offset'] - row['onset']\n",
    "    audiodata.append((name, cat, duration) + audio_props)\n",
    "\n",
    "# Convert into a Pandas dataframe\n",
    "audiodatadf = pd.DataFrame(audiodata, columns=['file', 'class', 'duration', 'channels','sample_rate','bit_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-array",
   "metadata": {},
   "source": [
    "### Audio duration visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "velvet-woman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(audiodatadf['duration'], rwidth=0.9, color='#86bf91')\n",
    "\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Histogram of audio lengths')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-electricity",
   "metadata": {},
   "source": [
    "### Audio channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alone-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio channels:\n",
      "\n",
      "1    1.0\n",
      "Name: channels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Audio channels:\\n\")\n",
    "print(audiodatadf.channels.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-tyler",
   "metadata": {},
   "source": [
    "### Bit depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "portable-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit depths:\n",
      "\n",
      "32    1.0\n",
      "Name: bit_depth, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Bit depths:\\n\")\n",
    "print(audiodatadf.bit_depth.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-personal",
   "metadata": {},
   "source": [
    "### Sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "entitled-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rates:\n",
      "\n",
      "44100    1.0\n",
      "Name: sample_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample rates:\\n\")\n",
    "print(audiodatadf.sample_rate.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-scenario",
   "metadata": {},
   "source": [
    "## 4 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verbal-understanding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing element  0\n",
      "processing element  10\n",
      "processing element  20\n",
      "processing element  30\n",
      "processing element  40\n",
      "processing element  50\n",
      "processing element  60\n",
      "processing element  70\n",
      "processing element  80\n",
      "processing element  90\n",
      "Extracted a total of 3376 features vectors\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "#import librosa.display\n",
    "import librosa\n",
    "\n",
    "directory = 'E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\audio\\\\'\n",
    "\n",
    "features = []\n",
    "num_frames = []\n",
    "\n",
    "#length of splitted subvectors\n",
    "length = 1024\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for i in range(100):\n",
    "    \n",
    "    if i%10==0:\n",
    "        print(\"processing element \",i)\n",
    "    \n",
    "    file_name = directory+'TUT-SED-synthetic-2016-mix-'+str(i)+'.wav'\n",
    "        \n",
    "    # load single audio file\n",
    "    audio, sr = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    \n",
    "    # extract mfcc features with 20ms frame and 50% overlap at 22050 Hz\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40, n_fft=440, hop_length=220, n_mels=40)\n",
    "    \n",
    "    # save audio number of frames for labelling process\n",
    "    num_frames.append(mfccs.shape[1])\n",
    "    \n",
    "    # create subvectors of length and pad the last to length\n",
    "    for j in range(int(mfccs.shape[1]/length)+1):\n",
    "        \n",
    "        # subdivide in 1024 elements vectors\n",
    "        feat = mfccs[:,j*length:(j+1)*length]\n",
    "        \n",
    "        # last vector need padding\n",
    "        if feat.shape[1] != length:\n",
    "            feat = np.pad(feat, pad_width=((0, 0), (0, length-feat.shape[1])), mode='constant')\n",
    "        \n",
    "        feat = feat.transpose()\n",
    "        \n",
    "        # add new splitted vectors to features list\n",
    "        features.append(feat)\n",
    "\n",
    "print('Extracted a total of', len(features), 'features vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-calcium",
   "metadata": {},
   "source": [
    "## 5 Data labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing element  0\n",
      "processing element  10\n",
      "processing element  20\n",
      "processing element  30\n",
      "processing element  40\n",
      "processing element  50\n",
      "processing element  60\n",
      "processing element  70\n",
      "processing element  80\n",
      "processing element  90\n"
     ]
    }
   ],
   "source": [
    "#labelling matrix creation, this is done due to poliphony of data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_classes = meta['label'].nunique()\n",
    "labels = []\n",
    "\n",
    "#length of splitted subvectors\n",
    "length = 1024\n",
    "\n",
    "# to transform literal label to a numerical value\n",
    "label_switch = {\"alarms_and_sirens\" : 0,\n",
    "                \"baby_crying\" : 1,\n",
    "                \"bird_singing\" : 2,\n",
    "                \"bus\" : 3,\n",
    "                \"cat_meowing\" : 4,\n",
    "                \"crowd_applause\" : 5,\n",
    "                \"crowd_cheering\" : 6,\n",
    "                \"dog_barking\" : 7,\n",
    "                \"footsteps\" : 8,\n",
    "                \"glass_smash\" : 9,\n",
    "                \"gun_shot\" : 10,\n",
    "                \"horsewalk\" : 11,\n",
    "                \"mixer\" : 12,\n",
    "                \"motorcycle\" : 13,\n",
    "                \"rain\" : 14,\n",
    "                \"thunder\" : 15,        \n",
    "}\n",
    "\n",
    "# iterate over each file and create labels based on meta file\n",
    "for i in range(100):\n",
    "    \n",
    "    if i%10==0:\n",
    "        print(\"processing element \",i)\n",
    "        \n",
    "    file_name = directory+'TUT-SED-synthetic-2016-mix-'+str(i)+'.wav'\n",
    "\n",
    "    # initialize matrices with zeros\n",
    "    single_labels = np.zeros((num_classes, num_frames[i]), dtype=int)\n",
    "\n",
    "    # extract metadata of single audio file\n",
    "    query_name = file_name[len('E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\audio\\\\'):]\n",
    "    query_name = 'audio/' + query_name\n",
    "    subdf = meta.query('file==@query_name')\n",
    "    \n",
    "    # populate matrix based on meta file\n",
    "    # more efficient to do it starting from metafile instead of iterating on the matrix since \n",
    "    # features are less than the matrix and there are more zeros than ones at the end of \n",
    "    # the process\n",
    "    onset = np.array(subdf.loc[:, 'onset'])\n",
    "    offset = np.array(subdf.loc[:, 'offset'])\n",
    "    labeldf = np.array(subdf.loc[:, 'label'])\n",
    "    \n",
    "    for j in range(onset.shape[0]):\n",
    "        # metadata values are in seconds so transform in 10ms intervals\n",
    "        start = int(onset[j]*100)\n",
    "        end = int(offset[j]*100)\n",
    "        # label based on start and end of the single audio\n",
    "        for k in range(end-start):\n",
    "            single_labels[label_switch[labeldf[j]]][k+start] = 1\n",
    "           \n",
    "    # create subvectors of length and pad the last to length\n",
    "    for j in range(int(single_labels.shape[1]/length)+1):\n",
    "        \n",
    "        # subdivide in 1024 elements vectors\n",
    "        lab = single_labels[:,j*length:(j+1)*length]\n",
    "        \n",
    "        # last vector need padding\n",
    "        if lab.shape[1] != length:\n",
    "            lab = np.pad(lab, pad_width=((0, 0), (0, length-lab.shape[1])), mode='constant')\n",
    "        \n",
    "        lab = lab.transpose()\n",
    "        \n",
    "        # add new splitted vectors to labels list\n",
    "        labels.append(lab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-chrome",
   "metadata": {},
   "source": [
    "## 6 Preprocessed data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-trick",
   "metadata": {},
   "source": [
    "### Create dataframe to manipulate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collective-cargo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset contains 3376  files\n"
     ]
    }
   ],
   "source": [
    "# create empty data frame in pandas\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# add features\n",
    "dataframe['feature']  = features\n",
    "\n",
    "# add labels\n",
    "dataframe['class_label']  = labels\n",
    "\n",
    "print('Total dataset contains', len(dataframe), ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-escape",
   "metadata": {},
   "source": [
    "### Save processed data to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expensive-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_pickle('E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\processed_data_frame_new.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-constitution",
   "metadata": {},
   "source": [
    "### Delete unused variable to save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_selective -f features\n",
    "reset_selective -f labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-nelson",
   "metadata": {},
   "source": [
    "### Load processed data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "northern-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported 3376 elements\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_pickle('E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\processed_data_frame_new.pkl')\n",
    "print(\"imported\", dataframe.shape[0],\"elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-midnight",
   "metadata": {},
   "source": [
    "### Process data to input the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "internal-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(dataframe.feature.tolist())\n",
    "y = np.array(dataframe.class_label.tolist())\n",
    "\n",
    "# no need to encode labels since they are already in form of one hot encode\n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# delete X to save memory\n",
    "#reset_selective -f X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-paste",
   "metadata": {},
   "source": [
    "### Delete dataframe to save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structured-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_selective -f dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-seating",
   "metadata": {},
   "source": [
    "## 7 Models definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-average",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intended-provision",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_gfx1010.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024, 40, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1024, 40, 256)     6656      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024, 40, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024, 40, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1024, 8, 256)      1638656   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024, 8, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1024, 2, 256)      1638656   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1024, 256)         0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 1024, 256)         393984    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024, 16)          4112      \n",
      "=================================================================\n",
      "Total params: 3,685,136\n",
      "Trainable params: 3,683,600\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, Reshape, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = X.shape[1]\n",
    "num_columns = X.shape[2]\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = y.shape[2]\n",
    "\n",
    "def Net():\n",
    "    \n",
    "    # input layer\n",
    "    inputs = Input(shape=(num_rows, num_columns, num_channels))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,5), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,4), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,2), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # reshape data to input recurrent layer\n",
    "    x = Reshape((1024, 256))(x)\n",
    "    \n",
    "    # GRU\n",
    "    x = GRU(256, return_sequences=True)(x)\n",
    "        \n",
    "    # classifier layer\n",
    "    outputs = Dense(num_labels,activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model = Model(inputs, outputs)                            \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-sample",
   "metadata": {},
   "source": [
    "### Dessed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "waiting-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_gfx1010.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024, 40, 1)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 1028, 44, 1)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 1024, 40, 256)     537       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024, 40, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024, 40, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 1028, 12, 256)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 1024, 8, 256)      72192     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024, 8, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 1028, 6, 256)      0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 1024, 2, 256)      72192     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1024, 256)         0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 1024, 256)         393984    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024, 16)          4112      \n",
      "=================================================================\n",
      "Total params: 546,089\n",
      "Trainable params: 544,553\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, Reshape, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = X.shape[1]\n",
    "num_columns = X.shape[2]\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = y.shape[2]\n",
    "\n",
    "def Net():\n",
    "    \n",
    "    # input layer\n",
    "    inputs = Input(shape=(num_rows, num_columns, num_channels))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    x = ZeroPadding2D(padding=(2))(inputs)\n",
    "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before due to its special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before due to its special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Reshape((1024, 256))(x)\n",
    "    \n",
    "    # GRU\n",
    "    x = GRU(256, return_sequences=True)(x)\n",
    "        \n",
    "    # classifier layer\n",
    "    outputs = Dense(num_labels,activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model = Model(inputs, outputs)                            \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-today",
   "metadata": {},
   "source": [
    "### Baseline dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dental-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1024, 40, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1024, 40, 256)     6656      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024, 40, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024, 40, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1024, 8, 256)      1638656   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024, 8, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1024, 2, 256)      1638656   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 1024, 256, 1)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 1044, 256, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1024, 254, 256)    2560      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1024, 254, 256)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024, 254, 256)    1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1024, 85, 256)     65792     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1024, 21760)       0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024, 16)          348176    \n",
      "=================================================================\n",
      "Total params: 3,704,592\n",
      "Trainable params: 3,702,544\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = X.shape[1]\n",
    "num_columns = X.shape[2]\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = y.shape[2]\n",
    "\n",
    "def Net(dilated_kernel, dilation, dilated_padding):\n",
    "    \n",
    "    # input layer\n",
    "    inputs = Input(shape=(num_rows, num_columns, num_channels))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,5), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,4), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    x = Conv2D(256,kernel_size=(5,5), strides=(1,1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,2), padding='same')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # permute channels with feature \n",
    "    x = Permute((1,3,2))(x)\n",
    "    \n",
    "    # DIL-CNN \n",
    "    x = ZeroPadding2D(padding=(dilated_padding*dilation, 0))(x)\n",
    "    x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(dilation, 1))(x)#, strides=(1,3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (1,1), strides=(1,3))(x)\n",
    "    \n",
    "    # reshape to input the classifier\n",
    "    x = Reshape((1024, 256*85))(x)\n",
    "    \n",
    "    # classifier layer\n",
    "    outputs = Dense(num_labels,activation='sigmoid')(x)\n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model = Model(inputs, outputs)                            \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "dilated_kernel = (3,3)\n",
    "dilation = 10\n",
    "dilated_padding = 1\n",
    "model = Net(dilated_kernel,dilation,dilated_padding)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "### New proposed model (dessed_dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aboriginal-yellow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1024, 40, 1)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 1028, 44, 1)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 1024, 40, 256)     537       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024, 40, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024, 40, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 1028, 12, 256)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 1024, 8, 256)      72192     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1024, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1024, 8, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 1028, 6, 256)      0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 1024, 2, 256)      72192     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1024, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "permute_3 (Permute)          (None, 1024, 256, 1)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 1044, 256, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1024, 254, 256)    2560      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1024, 254, 256)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024, 254, 256)    1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1024, 84, 256)     0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 1024, 21504)       0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024, 16)          344080    \n",
      "=================================================================\n",
      "Total params: 495,657\n",
      "Trainable params: 493,609\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SeparableConv2D, ZeroPadding2D, Activation, Dropout, Dense, \\\n",
    "                            Conv2D, MaxPooling2D, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import Input, optimizers\n",
    "\n",
    "num_rows = X.shape[1]\n",
    "num_columns = X.shape[2]\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = y.shape[2]\n",
    "\n",
    "def Net(dilated_kernel, dilation, dilated_padding):\n",
    "    \n",
    "    # input layer\n",
    "    inputs = Input(shape=(num_rows, num_columns, num_channels))\n",
    "    \n",
    "    # DWS-CNN layer 1\n",
    "    x = ZeroPadding2D(padding=(2))(inputs)\n",
    "    # use valid padding since padding is introduced before due to its special form (maybe it's equal to use same padding?)\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,5), strides=(1,5), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 2\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before due to its special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,4), strides=(1,4), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # DWS-CNN layer 3\n",
    "    x = ZeroPadding2D(padding=(2))(x)\n",
    "    # use valid padding since padding is introduced before due to its special form\n",
    "    x = SeparableConv2D(256,kernel_size=(5,5), strides=(1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    x = BatchNormalization()(x)\n",
    "    # Pooling\n",
    "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='valid')(x)\n",
    "    # Dropout\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # permute channels with feature \n",
    "    x = Permute((1,3,2))(x)\n",
    "        \n",
    "    # DIL-CNN \n",
    "    x = ZeroPadding2D(padding=(dilated_padding*dilation, 0))(x)\n",
    "    x = Conv2D(256, kernel_size=dilated_kernel, dilation_rate=(dilation, 1))(x)#, strides=(1,3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #initializer = keras.initializers.Ones()\n",
    "    #x = Conv2D(256, (1,1), strides=(1,3), kernel_initializer=initializer, trainable = False)(x)\n",
    "    x = MaxPooling2D(pool_size=(1,3), strides=(1,3), padding='valid')(x)\n",
    "    \n",
    "    # reshape to input the classifier\n",
    "    x = Reshape((1024, 256*84))(x)\n",
    "    \n",
    "    # classifier layer\n",
    "    outputs = Dense(num_labels,activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "    # model compilation for training\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    model = Model(inputs, outputs)                            \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"binary_accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "dilated_kernel = (3,3)\n",
    "dilation = 10\n",
    "dilated_padding = 1\n",
    "model = Net(dilated_kernel,dilation,dilated_padding)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-precipitation",
   "metadata": {},
   "source": [
    "## 8 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2268 samples, validate on 432 samples\n",
      "Epoch 1/250\n",
      "2268/2268 [==============================] - 243s 107ms/step - loss: 0.2576 - binary_accuracy: 0.9259 - val_loss: 0.2700 - val_binary_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26997, saving model to E:\\Xception\\TUT-SED-synthetic-2016\\model-0.27.h5\n",
      "Epoch 2/250\n",
      " 599/2268 [======>.......................] - ETA: 3:07 - loss: 0.2618 - binary_accuracy: 0.9250"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 250\n",
    "# low batch size due to memory maximum dimension, modify if using smaller dataset or larger VRAM\n",
    "num_batch_size = 1\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\model-{val_loss:.2f}.h5', \n",
    "                               verbose=1, save_best_only=True, monitor=\"val_loss\"),\n",
    "                EarlyStopping(monitor='val_loss', patience=30)]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_split=0.16, verbose=1, callbacks=callbacks)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-absolute",
   "metadata": {},
   "source": [
    "## 9 Model save and load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-thirty",
   "metadata": {},
   "source": [
    "### Save model of last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\93epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-cleveland",
   "metadata": {},
   "source": [
    "### Import saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model('E:\\\\Xception\\\\TUT-SED-synthetic-2016\\\\model-0.24.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-subsection",
   "metadata": {},
   "source": [
    "## 10 Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-corporation",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=num_batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-worry",
   "metadata": {},
   "source": [
    "### Plot training graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-essay",
   "metadata": {},
   "source": [
    "### Evaluate precision as micro averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "official-jumping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/676 [==============================] - 27s 39ms/step\n",
      "processing element  0\n",
      "processing element  100\n",
      "processing element  200\n",
      "processing element  300\n",
      "processing element  400\n",
      "processing element  500\n",
      "processing element  600\n",
      "recall:  0.0041410299343732975\n",
      "precision:  0.07003381234150464\n",
      "f1:  0.007819689383249727\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "y_pred = model.predict(x_test, batch_size=8, verbose=1)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print(\"processing element \", i)\n",
    "    for j in range(y_test.shape[1]):\n",
    "        for k in range(y_test.shape[2]):\n",
    "            \n",
    "            test = y_test[i][j][k]\n",
    "            pred = y_pred[i][j][k]\n",
    "            \n",
    "            # binarization of predicted output\n",
    "            if(pred >= 0.5):\n",
    "                pred = 1\n",
    "            else:\n",
    "                pred = 0\n",
    "\n",
    "            if(test == 1 and pred == 1):\n",
    "                TP = TP + 1\n",
    "            elif(test == 0 and pred == 1):\n",
    "                FP = FP + 1\n",
    "            elif(test == 0 and pred == 0):\n",
    "                TN = TN + 1\n",
    "            elif(test == 1 and pred == 0):\n",
    "                FN = FN + 1\n",
    "                \n",
    "recall = TP/(TP+FN)\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "\n",
    "f1_score = 2*recall*precision/(recall+precision)\n",
    "\n",
    "print(\"recall: \", recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"f1: \", f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
